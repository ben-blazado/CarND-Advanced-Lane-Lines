{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Standard Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finder Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alf_cam\n",
    "import alf_enh\n",
    "import alf_war\n",
    "import alf_llg\n",
    "import alf_hud\n",
    "import alf_con\n",
    "import alf_utils\n",
    "\n",
    "alf_utils.init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main controller\n",
    "ctrlr = alf_con.Controller()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_video__OLD__ = {\n",
    "    'filename'   : 'project_video.mp4',\n",
    "    'sob_min_x'  : 5,\n",
    "    'y_min_s'    : 57,  \n",
    "    'y_min_v'    : 220,\n",
    "    'w_max_s'    : 25,\n",
    "    'w_min_v'    : 201,\n",
    "    'max_coeffs' : 50,\n",
    "    'min_samples': 3,\n",
    "    'N'          : 12,\n",
    "    'coeff_bias' : 0.9,\n",
    "    'clip_start' : None,\n",
    "    'clip_end'   : None,\n",
    "    'stage'      : 1,\n",
    "    'output'     : 'project_video.mp4'\n",
    "}\n",
    "\n",
    "project_video = {\n",
    "    'filename'   : 'project_video.mp4',\n",
    "    # 0 for max sensitivity to gradients\n",
    "    'sob_min_x'  : 5,\n",
    "    # yellow\n",
    "    'y_min_s'    : 76,    \n",
    "    'y_min_v'    : 96,\n",
    "    # white\n",
    "    'w_max_s'    : 30,\n",
    "    'w_min_v'    : 202,   \n",
    "    # smoothing\n",
    "    'max_coeffs' : 50,\n",
    "    'min_samples': 3,\n",
    "    'N'          : 12,\n",
    "    'coeff_bias' : 0.9,\n",
    "    'clip_start' : None,\n",
    "    'clip_end'   : None,\n",
    "    'stage'      : 5,\n",
    "    'output'     : 'project_video.mp4'\n",
    "}\n",
    "\n",
    "\n",
    "ctrlr = alf_con.Controller()\n",
    "ctrlr.processVideo(project_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_video = {\n",
    "    'filename'   : 'challenge_video.mp4',\n",
    "    'sob_min_x'  : 10, \n",
    "    'y_min_s'    : 25,  \n",
    "    'y_min_v'    : 150,\n",
    "    'w_max_s'    : 12, \n",
    "    'w_min_v'    : 158,\n",
    "    'max_coeffs' : 15,\n",
    "    'min_samples': 3,\n",
    "    'N'          : 3,\n",
    "    'coeff_bias' : 0.9,\n",
    "    'clip_start' : None,\n",
    "    'clip_end'   : None,\n",
    "    'stage'      : 5,\n",
    "    'output'     : 'challenge_video.mp4'\n",
    "}\n",
    "\n",
    "ctrlr = alf_con.Controller()\n",
    "ctrlr.processVideo(challenge_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harder_challenge_video = {\n",
    "    'filename'   : 'harder_challenge_video.mp4',\n",
    "    'sob_min_x'  : 10, # tried: 5\n",
    "    'y_min_s'    : 128, # tried: 87\n",
    "    'y_min_v'    : 230, \n",
    "    'w_max_s'    : 15, # tried: 12, 25 \n",
    "    'w_min_v'    : 200, # tried: 158, 125\n",
    "    'max_coeffs' : 60,\n",
    "    'min_samples': 3,\n",
    "    'N'          : 12,\n",
    "    'coeff_bias' : 0.9,\n",
    "    'clip_start' : None,\n",
    "    'clip_end'   : None,\n",
    "    'stage'      : 5,\n",
    "    'output'     : 'harder_challenge_video.mp4'\n",
    "}  \n",
    "ctrlr = alf_con.Controller()\n",
    "ctrlr.processVideo(harder_challenge_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf_utils.demoChessboardCorners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf_utils.demoCameraCalibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf_utils.createUndistStraight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"test_images/test5.jpg\")\n",
    "alf_utils.demoWarpImage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"test_images/test5.jpg\")\n",
    "alf_utils.demoEnhance(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"test_images/test5.jpg\")\n",
    "alf_utils.demoLaneSearch(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(\"test_images/test5.jpg\")\n",
    "alf_utils.demoCompose(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf_utils.shutdown_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alf_cam\n",
    "\n",
    "\n",
    "\n",
    "cam = alf_cam.Camera()\n",
    "cam.calibrate()\n",
    "cam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import alf_cam\n",
    "init_logging()\n",
    "cam  = alf_cam.Camera()\n",
    "cam.calibrateCamera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import alf_enh\n",
    "import alf_war\n",
    "import alf_llg\n",
    "import alf_hud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writeup.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-JAN-2021\n",
    "# Advanced Computer Lane Finding \n",
    "Implement a video processing pipeline that detects road lanes.\n",
    "\n",
    "\n",
    "## Goals\n",
    "- Correct image distortion by computing the camera matrix and distortion coefficients.\n",
    "- Enhance lane pixels by applying  color transforms and gradients. \n",
    "- Apply a perspective transform to rectify image to a top-down view of road.\n",
    "- Identify lane pixels and fit into a 2-degree polynomial to represent a lane.\n",
    "- Calculate a radius of curvature and position of vehicle with respect to center.\n",
    "- Compose an image that clearly identifies the lane area.\n",
    "- Fulfill a requirement of the Udacity Self-Driving Car Engineer Nanodegree Program.\n",
    "- Practice using the following: opencv, classes, modules, UML sketching, GRASP, and docstring.\n",
    "\n",
    "## Distortion correction\n",
    "Ensuring that straight lines in the real world appear straight in image space prevents false curves from being processed by later stages of the pipeline.\n",
    "\n",
    "### Chessboard Corners\n",
    "\n",
    "The opencv function `findChessboardCorners()` was used to calculate object points and image points representing the inner corners of multiple chessboard images:\n",
    "\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_cam.py\n",
    "###\n",
    "\n",
    "class ChessboardImage:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def findChessboardCorners(self):\n",
    "\n",
    "        ...\n",
    "        \n",
    "        gray = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)\n",
    "        corners_found, corners = cv2.findChessboardCorners(gray, (self.xdim, self.ydim), flags=None)\n",
    "        \n",
    "        if corners_found:\n",
    "        \n",
    "            ...\n",
    "            \n",
    "            self.objpoints = np.zeros(shape=(self.xdim * self.ydim, 3), dtype=np.float32)\n",
    "            self.objpoints[:, :2] = np.array([(x, y) for y in range(self.ydim) for x in range(self.xdim)])\n",
    "\t        self.imgpoints = corners\n",
    "            \n",
    "            ...\n",
    "            \n",
    "        return corners_found\n",
    "```\n",
    "\n",
    "Image below verifies the chessboard corners found:\n",
    "![Chessboard corners found](output_images/wup_corners_calibration13.png)\n",
    "\n",
    "### Camera Calibration\n",
    "\n",
    "The objpoints and imgpoints data were used to compute the camera matrix and distortion coefficients. Calibration is performed using the opencv function `calibrateCamera()`, then `undistort()` is called in the main pipeline which performs the actual distortion correction:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_cam.py\n",
    "###\n",
    "\n",
    "class Camera:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def calibrate(self, calibration_set=None):\n",
    "\n",
    "        ...\n",
    "    \n",
    "        if calibration_set is None:\n",
    "            calibration_set = ChessboardCameraCalibrationSet()\n",
    "            \n",
    "        objpoints, imgpoints, self.image_shape = calibration_set.getCalibrationParams ()\n",
    "        \n",
    "        #--- rotation and translation vectors not used for this project\n",
    "        cal_found, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, self.image_shape, None, None)\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        return\n",
    "        \n",
    "        ...\t\n",
    "        \n",
    "    def undistort(self, img):\n",
    "        img_undist = cv2.undistort(img, self.mtx, self.dist)\n",
    "        return img_undist\t\n",
    "```\n",
    "\n",
    "Image below verifies camera calibration. The apparent curve of straight lines due to lens distortion is corrected to appear straight in the output image:\n",
    "\n",
    "![](output_images/wup_camera_calibrate.png)\n",
    "\n",
    "## Image Enhancement\n",
    "Edge detection and color transformation is applied to the image corrected for distortion. Combining Sobel X-gradient and color space masks help pickout yellow and white lanes. \n",
    "\n",
    "### Sobel X-Gradient Masking\n",
    "\n",
    "The Sobel function helped with detecting lanes in low contrast areas where the lightness of the road was similar to the lightness of the lanes.  \n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_enh.py\n",
    "###\n",
    "\n",
    "class Enhancer:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def sobelXMask(self, img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, dx=1, dy=0))\n",
    "        sobel_scaled = np.uint8(255 * sobel / np.max(sobel))\n",
    "       \n",
    "        mask = np.zeros_like(sobel_scaled)\n",
    "       \n",
    "        # activate (set to \"1\") all pixels that meet the x gradient thresholds\n",
    "        mask[(self.sob_min_x <= sobel_scaled) & (sobel_scaled <= 255)] = 1\n",
    "       \n",
    "        return mask\n",
    "```\n",
    "\n",
    "### HSV Color Masking\n",
    "\n",
    "The color transforms were done in the HSV colorspace because the image editing tools used to idenfity the color values worked in the HSV space. Yellow and white lane masks are combined with a bitwise OR:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_enh.py\n",
    "###\n",
    "\n",
    "class Enhancer:\n",
    "\n",
    "    ...\n",
    "\n",
    "    def laneMask(self, img):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        h = hsv[:,:,0] # h-channel\n",
    "        s = hsv[:,:,1] # s-channel\n",
    "        v = hsv[:,:,2] # v-channel\n",
    "\n",
    "        # mask for yellow lane\n",
    "        y_mask = np.zeros_like(s)\n",
    "        y_h = (10 <= h) & (h <= 25)\n",
    "        y_s = s > self.y_min_s\n",
    "        y_v = v > self.y_min_v\n",
    "        y_mask [(y_h & y_s & y_v)] = 1\n",
    "\n",
    "        # mask for white lane\n",
    "        w_mask = np.zeros_like(s)\n",
    "        w_s = s < self.w_max_s\n",
    "        w_v = self.w_min_v < v\n",
    "        w_mask[(w_s & w_v)] = 1\n",
    "\n",
    "        return y_mask | w_mask\n",
    "```\n",
    "\n",
    "### Combining Masks\n",
    "\n",
    "The sobel x-gradient mask is combined with the lane mask with bitwise AND: \n",
    "\n",
    "```\n",
    "### \n",
    "### Code location: alf_enh.py:\n",
    "###\n",
    "\n",
    "class Enhancer:\n",
    "    ...\n",
    "    def enhance(self, img):\n",
    "        sobel_mask = self.sobelXMask (img)\n",
    "        lane_mask = self.laneMask(img)       \n",
    "        return sobel_mask & lane_mask\n",
    "```\n",
    "\n",
    "If edge detection was not performed, the image would look like random noise in those low contrast, similarly colored areas. If the sobel mask was combined using a bitwise OR, we would get additional noise that would make it difficult for the later stages to pickout the lane. Keeping a low edge detection threshold helped pick out the lanes where the values and saturation of the white lanes were similar with light colored concrete:\n",
    "\n",
    "![](output_images/wup_enhancer.jpg)\n",
    "\n",
    "## Top-down View\n",
    "The perspective of the road area is transformed to a top-down view prior to lane pixel search and detection. To select the region, an undistorted image of a straight section of road is taken, and a line was drawn with an image editor to coincide with one of the straight lanes. The other line is derived from taking the inverse slope of the first and the four points of the trapezoid are then read from the image editor. In the actual pipeline, the trapezoidal region is transformed after the edge detection and color transformation masks are applied. A rectangular region is then plotted to which the trapezoid is transformed:\n",
    "\n",
    "![](output_images/wup_topdown.png)\n",
    "\n",
    "The trapezoidal region of the source image and the rectangular region of the destination is used to compute the perspective transformation matrix, `M`, to achieve a top down view using opencv's `warpPerspective()`. Its inverse, `invM`, is used to transform the top down view back into the original perspective on the road image using `unwarpPerspective()` in the final stage of the pipeline:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_enh.py\n",
    "### \n",
    "\n",
    "class Warper:\n",
    "    ...\n",
    "    def calibrate(self):\n",
    "        # M: transformation matrix\n",
    "        self.M = cv2.getPerspectiveTransform(self.calibration_set.src_points, \n",
    "                                            self.calibration_set.dst_points)\n",
    "        # use invM when unwarping image\n",
    "        self.invM = cv2.getPerspectiveTransform(self.calibration_set.dst_points, \n",
    "                                                self.calibration_set.src_points)\n",
    "        return\n",
    "\n",
    "    def warpPerspective(self, img):\n",
    "        img_warped = cv2.warpPerspective(img, self.M, \n",
    "              (img.shape[1], img.shape[0]), \n",
    "              flags=cv2.INTER_LINEAR)\n",
    "        return img_warped\n",
    "    \n",
    "    def warpPerspective(self, img):\n",
    "        img_unwarped = cv2.warpPerspective(img, self.invM, \n",
    "             (img.shape[1], img.shape[0]), \n",
    "             flags=cv2.INTER_LINEAR)\n",
    "        return img_unwarped\n",
    "```\n",
    "\n",
    "## Lane Pixel Identification and Line Fitting\n",
    "\n",
    "A \"sliding window\" search area and, when a line was successfully found in a previous frame, a \"linear window\" was used to gather pixels associated with a lane. It used the top down binary image from the warp (perspective transformation) stage to identify lane pixels.\n",
    "\n",
    "### Sliding Window Search Area\n",
    "\n",
    "The \"sliding window\" search area defined a rectangle, `(x1, y1, x2, y2)`, which starts at the base of the image and progressively \"slides\" up the image to gather lane pixels within the boundaries of the rectangle. The lane pixels are gathers in separate x and y position arrays `lane_points_x` and `lane_points_`. The horizontal (x) position of the rectangle is adjusted to the average x position of all pixels found if a threshold number of points was reached. Also, if not enough pixels were found the window is slid in the last direction of found pixels so that it just does not slide upwards. Rather, it slides in the direction the previous window slid. The sliding stops once it reaches the top (when y1 == 0). \n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_llg.py\n",
    "###\n",
    "\n",
    "class SlidingWindow:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def findPoints(self):\n",
    "   \n",
    "        while not self.passed_top:        \n",
    "           \n",
    "            self.window_history.append([self.x1, self.y1, self.x2, self.y2])\n",
    "           \n",
    "            # mask in all points within window by x and y values\n",
    "            x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "            y_bool_mask = (self.y1 <= self.image_points_y) & (self.image_points_y <= self.y2)\n",
    "\n",
    "            # bit wise the x and y masks to get the actual points\n",
    "            xy_bool_mask = (x_bool_mask) & (y_bool_mask)\n",
    "\n",
    "            # apply mask to image_points_x and _y to find the points that are in window region\n",
    "            points_found_x = self.image_points_x[xy_bool_mask]\n",
    "            points_found_y = self.image_points_y[xy_bool_mask]\n",
    "\n",
    "            # collect the points found into lane_points_x and _y\n",
    "            self.lane_points_x.extend(points_found_x)\n",
    "            self.lane_points_y.extend(points_found_y)\n",
    "\n",
    "            # update the midpoint if enough points found above threshold\n",
    "            if len(points_found_x) >= self.numpoints_found_thresh:\n",
    "                new_x_mid = np.int(np.average(points_found_x))\n",
    "                self.x_dir = new_x_mid - self.x_mid\n",
    "                self.x_mid = new_x_mid\n",
    "            elif (len(points_found_x) < self.numpoints_found_thresh // 3 and self.x_dir is not None):\n",
    "                self.x_mid += self.x_dir\n",
    "\n",
    "            self.slideUp()\n",
    "       \n",
    "        return (self.lane_points_x, self.lane_points_y)\n",
    "```\n",
    "\n",
    "### Line Fitting\n",
    "\n",
    "The lane points in separate x and y arrays are then used to find a line that best represents the lane using numpy's `polyfit()`:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_llg.py\n",
    "###\n",
    "\n",
    "class Line:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def fit(self, x_points, y_points):\n",
    "        self.pts = None    \n",
    "        self.x = None\n",
    "        self.y = None \n",
    "        self.found = False \n",
    "        tries = 0\n",
    "        max_tries = 3\n",
    "        while tries < max_tries and not self.found:\n",
    "            tries += 1\n",
    "            try:\n",
    "                # remember we solve for X!!! i.e. x = ay^2 + by + c\n",
    "                coeffs = np.polyfit(y_points, x_points, deg=2)\n",
    "                if tries > 1:\n",
    "                    msg = \"Polyfit succeeded on try {}.\"\n",
    "                    self.logger.debug(msg.format(tries))\n",
    "                self.found = True\n",
    "            \n",
    "            except Exception as e:\n",
    "                if tries < max_tries:\n",
    "                    msg = \"Polyfit failed: {}. Trying again.\"\n",
    "                    self.logger.debug(msg.format(e))\n",
    "                else:\n",
    "                    msg = \"Polyfit failed to fit a line. {}.\"\n",
    "                    self.logger.debug(msg.format(e))\n",
    "                    \n",
    "        if self.found:\n",
    "            self.coeffs = coeffs\n",
    "        else:\n",
    "            self.coeffs = None\n",
    "            \n",
    "        return\n",
    "```\n",
    "\n",
    "### Smoothing\n",
    "\n",
    "Once a fit has been determined, the line goes through a smoothing process which adjusts the coefficients to a weighted average of previous coefficients. If the fit is not within a specified `N` standard deviations of the average of previous coeffs, the most recent set of coefficients is used for the current line:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_llg.py\n",
    "###\n",
    "\n",
    "class Line:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def smooth (self):\n",
    "        \n",
    "        good_fit = False\n",
    "        \n",
    "        if self.prev_coeffs:\n",
    "            \n",
    "            avg_prev_coeffs = np.average(self.prev_coeffs, axis=0)\n",
    "            \n",
    "            if self.found:\n",
    "                \n",
    "                if len (self.prev_coeffs) > self.min_samples:\n",
    "                    # see if coeff of line is within std devs of avg \n",
    "                    # of previous lines \n",
    "                    std_prev_coeffs = np.std(self.prev_coeffs, axis=0)\n",
    "                    in_range = (abs(self.coeffs - avg_prev_coeffs) \n",
    "                               < self.N*std_prev_coeffs)\n",
    "                else:\n",
    "                    in_range = [True]\n",
    "                    \n",
    "                good_fit = all (in_range)\n",
    "\n",
    "                if good_fit:\n",
    "                    self.logger.debug(\"Line fit seems ok.\")\n",
    "                    # coeffs use avg prev coeffs based on bias\n",
    "                    # set coeff bias to 1 to prevent bias from prev coeffs\n",
    "                    self.coeffs = (self.coeff_bias*self.coeffs\n",
    "                                  + (1-self.coeff_bias)*avg_prev_coeffs)\n",
    "                    self.prev_coeffs.append(self.coeffs) \n",
    "                    if len(self.prev_coeffs) > self.max_coeffs:\n",
    "                        # pop first to remove oldest line from list to \n",
    "                        # prevent being include in average\n",
    "                        self.prev_coeffs.pop(0)\n",
    "                        msg = \"Coeff buffer full:{}. Removed oldest line.\"\n",
    "                        self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "                \n",
    "                else:\n",
    "                    self.logger.debug(\"Line fit looks off; \"\n",
    "                        + \"will use average of previous.\")\n",
    "                    self.coeffs = avg_prev_coeffs\n",
    "                    # set found to False since line fit was bad\n",
    "                    # remove oldest line; allows list of previous fits\n",
    "                    # to decay to nothing if consecutive bad lines are\n",
    "                    # are found\n",
    "                    self.prev_coeffs.pop(0)\n",
    "                    \n",
    "            else:\n",
    "                # line not found, use average of previous coffecients \n",
    "                self.logger.debug(\"Line was not found! \"\n",
    "                    + \"Using average of old lines.\")\n",
    "                self.coeffs = avg_prev_coeffs                \n",
    "                self.prev_coeffs.pop(0)\n",
    "                # set found to True since we \"found\" a line \n",
    "                # using the average of previous coeffs\n",
    "                \n",
    "        elif self.found:\n",
    "            # first coeff to add to list! \n",
    "            good_fit = True\n",
    "            # don't smooth since there is nothing to smooth to\n",
    "            self.prev_coeffs.append(self.coeffs) \n",
    "            \n",
    "        msg = \"Number of old lines/coeffs: {}.\"\n",
    "        self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "            \n",
    "        return good_fit\n",
    "```\n",
    "\n",
    "### Sliding Window Search Area Detections\n",
    "\n",
    "The coefficients of the line can then be used to represent the real world lane. Below is an example of the sliding windows (green), detected pixels (yellow and blue), and lane lines (red):\n",
    "\n",
    "![](output_images/wup_sliding_window.png)\n",
    "\n",
    "### Linear Window Search Area\n",
    "\n",
    "If a line has been found in a previous frame, a linear window search area is used. The borders of the search area are simply  offsets to either side of the line, `(LinearWindow.x1, LinearWindow.x2)`. Pixels are simply gathered for those that are within these linear borders:\n",
    "\n",
    "```\n",
    "### \n",
    "### Code location: alf_llg\n",
    "###\n",
    "\n",
    "class LinearWindow:\n",
    "    \n",
    "    def findPoints (self):\n",
    "        \n",
    "        # mask in all points within linear window by x values\n",
    "        x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "        \n",
    "        # apply mask to image_points_x and _y to find the points \n",
    "        # that are in linear window search area \n",
    "        points_found_x = self.image_points_x[x_bool_mask]\n",
    "        points_found_y = self.image_points_y[x_bool_mask]\n",
    "        \n",
    "        # collect the points found into lane_points_x and _y\n",
    "        self.lane_points_x.extend(points_found_x)\n",
    "        self.lane_points_y.extend(points_found_y)\n",
    "        \n",
    "        # the x coordinates of the line may be modified after line smoothing\n",
    "        # and may not reflect the original search area\n",
    "        # so save the x coordinates after find findpoints for use in paint\n",
    "        self.x_search_line = [self.line.lookupX(y) for y in range(self.ht)]\n",
    "        \n",
    "        return self.lane_points_x, self.lane_points_y    \n",
    "```\n",
    "\n",
    "### Linear Window Search Area Detections\n",
    "\n",
    "Below is an example of the linear windows search areas, the borders on each side, lane pixels detected within those borders, and the lines representing the lanes:\n",
    "\n",
    "![](output_images/wup_linear_window.png)\n",
    "\n",
    "### Lane Area\n",
    "\n",
    "With both lane lines detected, a polygon is formed which is filled to highlight the lane area:\n",
    "\n",
    "![](output_images/wup_lane_area.png)\n",
    "\n",
    "## Radius of Curvature and Center Offset\n",
    "\n",
    "To calculate the radius of curvature, the suggestion in *Lesson 8 - Measuring Curvature II* is used which allows us to skip doing another line fit since we are scaling the image space to real world space. The challenge is to derive the real world line coefficients from the existing coefficients in the pixel space (scale to meters from pixels).\n",
    "\n",
    "### Scaling Line Coefficients to Real World\n",
    "\n",
    "The goal is to find a_mtr, b_mtr, c_mtr in terms of corresponding values in pixel space and scaling factors, mx, my.\n",
    "\n",
    "Given:\n",
    "```\n",
    "y_mtr = my * y_pix  so: y_pix = y_mtr/my\n",
    "x_mtr = mx * x_pix  so: x_pix = x_mtr/mx\n",
    "```\n",
    "\n",
    "The line in the by the second degree polynomial in real world:\n",
    "```\n",
    "x_mtr = a_mtr*(y_mtr)**2 + b_mtr*y_mtr + c_mtr\n",
    "```\n",
    "\n",
    "Similarly, in pixel space:\n",
    "```\n",
    "x_pix = a_pix*(y_pix)**2 + b_pix*y_pix + c_pix\n",
    "```\n",
    "\n",
    "Substitute x_pix and y_pix:\n",
    "```\n",
    "x_mtr/mx = a_pix*(y_mtr/my)**2 + b_pix*(y_mtr/my) + c_pix\n",
    "```\n",
    "\n",
    "Arrange the y-scale factor, `my`:\n",
    "```\n",
    "x_mtr/mx = (a_pix/my**2)*(y_mtr)**2 + (b_pix/my)*(y_mtr) + c_pix\n",
    "```\n",
    "\n",
    "Multiply both sides by mx to solve for x_mtr:\n",
    "```\n",
    "x_mtr = mx*((a_pix/my**2)*(y_mtr)**2 + mx*(b_pix/my)*(y_mtr) + mx*c_pix\n",
    "```\n",
    "\n",
    "Arrange the x-scale factor, `mx`:\n",
    "```\n",
    "x_mtr = (a_pix*mx/my**2)*(y_mtr)**2 + (b_pix*mx/my)*(y_mtr) + mx*c_pix\n",
    "```\n",
    "\n",
    "But since: \n",
    "```\n",
    "x_mtr = a_mtr*(y_mtr)**2 + b_mtr*y_mtr + c_mtr\n",
    "```\n",
    "\n",
    "The coefficients in real_world (a_mtr, b_mtr, c_mtr) can be scaled in terms of their corresponding pixel coefficients using the following:\n",
    "```\n",
    "a_mtr = a_pix*mx/(my**2)\n",
    "b_mtr = b_pix*mx/my\n",
    "c_mtr = c_pix*mx\n",
    "```\n",
    "\n",
    "So scaling the pixel coefficients to real world coefficients can now be implemented, whilst skipping another call to polyfit using points scaled to real world (note we use the scaling factors, XM_PER_PIXEL and YM_PER_PIXEL) presented in the lesson:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_llg.py\n",
    "###\n",
    "\n",
    "# image to real space scaling default per lesson Measuring Curvature II\n",
    "# in meters per pixel; used in calculating radius of curvature\n",
    "# as well as offset center\n",
    "XM_PER_PIXEL = 3.7 / 700    \n",
    "YM_PER_PIXEL = 30 / 720\n",
    "\n",
    "\n",
    "class Line:\n",
    "\n",
    "    ...\n",
    "\n",
    "    def radius(self, y, xm_per_pix=None, ym_per_pix=None):\n",
    "        if not self.found:\n",
    "            return None\n",
    "        try:\n",
    "            # rescale coeffs and y to real world\n",
    "            a = self.coeffs[0] * xm_per_pix / ym_per_pix**2\n",
    "            b = self.coeffs[1] * xm_per_pix / ym_per_pix\n",
    "            y = y * ym_per_pix    # scale y to real-world!\n",
    "            R = (1 + (2*a*y + b)**2)**(3/2) / abs(2*a)\n",
    "            msg = \"Radius of curvature: {}.\"\n",
    "            self.logger.debug(msg.format(R))\n",
    "        except Exception as e:\n",
    "            msg = \"Error in calculating radius of curvature: {}.\"\n",
    "            self.logger.warning(msg.format(e))\n",
    "            R = None\n",
    "        return R\n",
    "```\n",
    "\n",
    "### Center Offset\n",
    "\n",
    "The x-coordinate of each line at the base of the image, `Line.baseX()`, is used to calculate the center x-coordinate between the two lanes, `lane_ceter`. It is then subtracted by the center coordinate of the screen, `img_ctr`, to calculate the offset of the vehicle from center line.\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_llg.py\n",
    "###\n",
    "class Line\n",
    "\n",
    "    ...\n",
    "\n",
    "    def baseX(self):\n",
    "        '''\n",
    "        Returns the x coordinate of the \"base\" of the line; i.e. at the bottom of image.\n",
    "        \n",
    "        Notes:\n",
    "        - Used in calculating offset from center for the lane finder\n",
    "        - Call generateXY() before calling this\n",
    "        - returns none if no line was found\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return None\n",
    "            \n",
    "        return self.x[-1]\n",
    "\n",
    "\n",
    "class AdvancedLaneFinder:\n",
    "\n",
    "    def centerOffset(self):\n",
    "        \n",
    "        img_ctr = self.binary_warped.shape[1] // 2\n",
    "        \n",
    "        t = 0    # sums up x values\n",
    "        n = 0    # count of number of samples\n",
    "\n",
    "        # get distance from center\n",
    "        x_left =  self.left_lane_line_finder.baseX()\n",
    "        t  += x_left if x_left is not None else 0\n",
    "        n  += 1 if x_left is not None else 0\n",
    "        \n",
    "        x_right = self.right_lane_line_finder.baseX()\n",
    "        t  += x_right if x_right is not None else 0\n",
    "        n  += 1 if x_right is not None else 0\n",
    "        \n",
    "        if n > 0:\n",
    "            lane_center = t / n\n",
    "            self.center_offset = (lane_center - img_ctr) * XM_PER_PIXEL\n",
    "        else:\n",
    "            self.center_offset = None\n",
    "            \n",
    "        msg = \"Center offset: {}.\"\n",
    "        self.logger.debug(msg.format(self.center_offset))\n",
    "            \n",
    "        return self.center_offset \n",
    "\n",
    "```\n",
    "\n",
    "## Final image composition\n",
    "\n",
    "Because the lane area is in the top down perspective, the main controller reuses the warper component to unwarped the lane area, then uses HUD (for Heads Up Display) component to blend the lane area with the original *undistorted* image, and write the radius of curvature and center offset.\n",
    "\n",
    "```\n",
    "\n",
    "###\n",
    "### Code location: alf_con.py \n",
    "###\n",
    "\n",
    "class Controller:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def processImg(self, img):\n",
    "    \n",
    "        ...\n",
    "        \n",
    "        unwarped_lanes      = self.war.unwarpPerspective(lane_area)\n",
    "        final_img           = self.hud.compose(img_undistorted, unwarped_lanes, rad, off)\n",
    "        \n",
    "        ...\n",
    "```\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_war.py\n",
    "###\n",
    "\n",
    "class Warper:\n",
    "\n",
    "    ...\n",
    "\n",
    "    def unwarpPerspective(self, img):\n",
    "        \n",
    "        img_unwarped = cv2.warpPerspective(img, self.invM, \n",
    "                (img.shape[1], img.shape[0]), \n",
    "                flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return img_unwarped\n",
    "```\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_hud.py\n",
    "###\n",
    "\n",
    "class HUD:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def blendImages(self, img_undistorted, unwarped_lanes):\n",
    "        \n",
    "        self.img_lane_area = cv2.addWeighted(img_undistorted, \n",
    "                                             alpha = 1.0, \n",
    "                                             src2  = unwarped_lanes, \n",
    "                                             beta  = 0.3, \n",
    "                                             gamma = 0.0)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def putRadius(self, rad):\n",
    "    \n",
    "        radius = rad\n",
    "        if radius is None:\n",
    "            rad_str = \"Radius:\"\n",
    "        elif radius >= 2000: \n",
    "            # we'll use around 2km for a road that feels straight\n",
    "            # min curve radius with superelevation 80mph 4575ft ~1.4km\n",
    "            # per U.S. government specifications for highway curvature: \n",
    "            # link: https://tinyurl.com/y42ulukp\n",
    "            rad_str = \"On straightaway\"\n",
    "        else:\n",
    "            msg = \"Radius: {:.2f} km\"\n",
    "            rad_str = msg.format (radius / 1000)\n",
    "        \n",
    "        cv2.putText(self.img_lane_area, rad_str, (50, 50), self.font, self.scale, self.color, self.thickness)\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def putCenterOffset(self, off):\n",
    "        \n",
    "        center_offset = off\n",
    "        if center_offset is None:\n",
    "            off_str = \"Center offset \"\n",
    "        else:\n",
    "            if abs (center_offset) < 0.1:  #--- 0.1 m or 10 cm\n",
    "                #--- if it's within 10cm it's on centerline...comeon!!!!\n",
    "                off_str = \"Roughly on centerline!\"\n",
    "            else:\n",
    "                if center_offset > 0:\n",
    "                    msg = \"Center Offset: {:.0f} cm Left\"\n",
    "                else:\n",
    "                    msg = \"Center Offset: {:.0f} cm Right\"\n",
    "                off_str = msg.format (abs(center_offset * 100))\n",
    "        \n",
    "        cv2.putText(self.img_lane_area, off_str, (50, 100), self.font, self.scale, self.color, self.thickness)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def compose(self, img_undistorted, unwarped_lanes, rad, off):\n",
    "        \n",
    "        self.blendImages(img_undistorted, unwarped_lanes)\n",
    "        \n",
    "        self.putRadius(rad)\n",
    "        self.putCenterOffset(off)\n",
    "        \n",
    "        return self.img_lane_area\n",
    "```\n",
    "\n",
    "The lane area, radius of curvature, center offset, and the original image are combined to compose the final image. \n",
    "\n",
    "![](output_images/wup_compose.png)\n",
    "\n",
    "## The Pipeline Overview\n",
    "The pipeline processes each frame of the road video as an individual image by performing the following functions mentioned in the previous sections:\n",
    "- Distortion correction that reduces apparent curvature of straight lines\n",
    "- Image enhancement that detects edges detection and transforms color values\n",
    "- Image transformation that results in a top down view of road\n",
    "- Lane area identification that identifies pixels belonging road lanes\n",
    "- Another image transformation that restores the top-down view of the lane area to the original perspective\n",
    "- Composing the original undistorted image with lane area, radius of curvature, and center offset\n",
    "\n",
    "It uses a `controller` to coordinate and sequence the various components of the pipeline:\n",
    "\n",
    "```\n",
    "###\n",
    "### Code location: alf_con.py \n",
    "###\n",
    "\n",
    "class Controller:\n",
    "\n",
    "    ...\n",
    "    \n",
    "    def processImg(self, img):\n",
    "    \n",
    "        ...\n",
    "        \n",
    "        srch_only           = (self.stage == 3)\n",
    "        img_undistorted     = self.cam.undistort(img)\n",
    "        binary              = self.enh.enhance(img_undistorted)    \n",
    "        binary_warped       = self.war.warpPerspective(binary)\n",
    "        lane_area, rad, off = self.alf.paintLaneArea(binary_warped, srch_only)\n",
    "        unwarped_lanes      = self.war.unwarpPerspective(lane_area)\n",
    "        final_img           = self.hud.compose(img_undistorted, unwarped_lanes, rad, off)\n",
    "        \n",
    "        ...\n",
    "        \n",
    "```\n",
    "\n",
    "### Project Video\n",
    "\n",
    "The pipeline appears to have succesfully identified the lane area and is located in the `output_images` folder with filename `project_video.mp4`: [output_images/project_video.mp4](./output_images/project_video.mp4)\n",
    "\n",
    "![](output_images/wup_project_video.png)\n",
    "\n",
    "### Pipeline Struggles, but Completes Challenge Video...\n",
    "The pipeline also appears to have succesfully worked on the challenge video. The output is located here: [output_images/challenge_video.mp4](output_project/challenge_video.mp4)\n",
    "\n",
    "![](output_images/wup_challenge_video.png)\n",
    "\n",
    "### ...and Fails Miserably on Harder Challenge Video\n",
    "The tight curves, brush and trees on either side of the road, dashboard glare, varied lighting conditions, and traffic were some of the challenges that prevented the pipeline from consistently detecting the lanes in this video:  [output_images/challenge_video.mp4](output_project/challenge_video.mp4)\n",
    "\n",
    "![](output_images/wup_harder_challenge_video.png)\n",
    "\n",
    "## Limitations, Issues, Challenges\n",
    "- Varied lighting conditions made it a challenge to find good HSV values that would help the pipeline detect lanes in all frames.\n",
    "- Dashboard glare detrimentally affects performance.\n",
    "- Camera lens aperture changes detrimentally affects performance (aperture appears to change from shadow area to light area).\n",
    "- There is no universal set of pipeline parameters. The pipeline parameters are tuned to a specific video. So the pipeline parameters for one video may not work on another.\n",
    "- Pipeline will fail on sudden, tight curves. \n",
    "- It will struggle on extended light colored roads; dried brush on side of road will fool pipeline into thinking it is a lane; guardrail on side of road looks like white lane.\n",
    "- Bumpy roads (such as going over a brdige) will change the perspective of the road and may make the lanes either coverge or diverge.\n",
    "\n",
    "## Areas of Improvement\n",
    "- Investigate use of CNN/YOLO to identify lane and edges of lane (and traffic!).\n",
    "- Identify center of road instead of lane markers.\n",
    "- Dynamically adjust pipeline parameters. Perhaps take the histogram of the bottom half of frame and stretch the HSV values to achieve better color, light and shadow separation.\n",
    "- Use some kind of A* search for lane pixels where search area is biased in direction of where more pixels are located.\n",
    "- Sensor-related: Use of a polarizing filter on camera to help with glare. Use constant aperture (don't go full auto on camera); mount camera on front of car sensor improvements; use lens hood; use some kind of 3-axis stabilization for sensor\n",
    "- Creating a virtual test track (ex: on Unreal Studio) will allow experimenting with perfect conditions to progressively worse conditions and may be a cost effective approach in further researching lane detecting algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Stuff\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(c):\n",
    "    avg = np.average(c)\n",
    "    lo = c.min()\n",
    "    hi = c.max()\n",
    "\n",
    "    below = c[c < avg]\n",
    "    below = 128 - 128 * (avg - below)/(avg - lo)\n",
    "    c[c < avg] = np.clip(below, 0, 255)\n",
    "\n",
    "    above = c[c >= avg]\n",
    "    above = 128 + 128 * (above - avg)/(hi - avg)\n",
    "    c[c >= avg] = np.clip(above, 0, 255)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "img = plt.imread(\"output_images/test.jpg\")\n",
    "\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "h = hsv[:,:,0] # h-channel\n",
    "s = hsv[:,:,1] # s-channel\n",
    "v = hsv[:,:,2] # v-channel\n",
    "\n",
    "avg = np.average(s)\n",
    "print(avg)\n",
    "\n",
    "lo = s.min()\n",
    "hi = s.max()\n",
    "avg, lo, hi\n",
    "\n",
    "\n",
    "'''\n",
    "if p < avg:\n",
    "    m = (avg - p) / (avg - lo)\n",
    "    o = 128 - 128 * m\n",
    "else:\n",
    "    # p > avg:\n",
    "    m = (p - avg) / (hi - avg)\n",
    "    o = 128 + 128 * m\n",
    "\n",
    "'''\n",
    "    \n",
    "stretch(s)\n",
    "stretch(v)\n",
    "\n",
    "rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(121).imshow(img)\n",
    "plt.subplot(122).imshow(rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 686\n",
    "y = 451\n",
    "m = 0.67191601049869\n",
    "b = y - m*x\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 719\n",
    "x = (y - b) / m\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -0.67191601049869\n",
    "b = 848.47769028871\n",
    "y = 719\n",
    "x = (y - b) / m\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_logging()\n",
    "enh  = alf_enh.Enhancer()\n",
    "imw  = alf_war.ImageWarper()\n",
    "alf  = alf_llg.AdvancedLaneFinder()\n",
    "hud  = alf_hud.HUD(alf, imw)\n",
    "\n",
    "#-------------------------------------------------\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    " \n",
    "def test_enh(img):\n",
    "    img_undistorted = cam.undistort(img)\n",
    "    binary          = enh.enhance(img_undistorted)    \n",
    "    \n",
    "    return binary\n",
    "    \n",
    "def test_war(img):\n",
    "\n",
    "    img_undistorted = cam.undistort(img)\n",
    "    binary          = enh.enhance(img_undistorted)    \n",
    "    binary_warped   = imw.warpPerspective(binary)\n",
    "    \n",
    "    return binary_warped\n",
    "\n",
    "def test_all(img):\n",
    "    img_undistorted = cam.undistort(img)\n",
    "    binary          = enh.enhance(img_undistorted)    \n",
    "    binary_warped   = imw.warpPerspective(binary)\n",
    "    alf.findLanes(binary_warped)  #--- TODO: change this\n",
    "    final_img       = hud.compose(img_undistorted)\n",
    "    return final_img\n",
    "    \n",
    "\n",
    "def process_image(img):\n",
    "\n",
    "    t = 2\n",
    "    tests = [test_enh, test_war, test_all]\n",
    "    result = tests[t](img)\n",
    "    \n",
    "    if len(result.shape) < 3:\n",
    "        return cv2.cvtColor(result * 255, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "\n",
    "v = 2\n",
    "\n",
    "video_sets = [\n",
    "    #--- 0 project sub\n",
    "    [\"project_video.mp4\", VideoFileClip(\"project_video.mp4\").subclip(t_start=21, t_end=27)],\n",
    "    \n",
    "    #--- 1 challenge sub\n",
    "    [\"challenge_video.mp4\", VideoFileClip(\"challenge_video.mp4\").subclip(0, 7)], \n",
    "    \n",
    "    #--- 2 project full\n",
    "    [\"project_video.mp4\", VideoFileClip(\"project_video.mp4\")],\n",
    "    \n",
    "    #--- 3 challenge all\n",
    "    [\"challenge_video.mp4\", VideoFileClip(\"challenge_video.mp4\")], \n",
    "    \n",
    "    #--- 4 harder challenge video\n",
    "    [\"harder_challenge_video.mp4\", VideoFileClip(\"harder_challenge_video.mp4\")],\n",
    "]\n",
    "\n",
    "\n",
    "#---------\n",
    "fname = video_sets[v][0]\n",
    "white_output = \"output_images/out_\" + fname\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "\n",
    "clip1 = video_sets[v][1]\n",
    "# clip1 = VideoFileClip(fname)\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10 - 1, -1, -1):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Module\n",
    "- ChessoardImage\n",
    "- ChessboardCameraCalibrationSet\n",
    "- Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessboardImage:\n",
    "    '''\n",
    "    An image of a chessboard used to calibrate Camera.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__: specify base, filename, and inner square dims of chessboad image.\n",
    "    - findChessboardCorners\n",
    "    \n",
    "    Notes:\n",
    "    - objpoints and imgpoints are used to calibrate camera.\n",
    "    - img_corners can be used to display the image to verify that corners were found correctly.\n",
    "    '''\n",
    "    \n",
    "    def __init__ (self, base_path, filename, inner_dims):\n",
    "        self.logger = logging.getLogger (\"ChessboardImage\")\n",
    "        \n",
    "        #--- RGB image of chessboard\n",
    "        self.img = mpimg.imread(base_path + filename)\n",
    "        self.filename = filename\n",
    "        \n",
    "        #---inner dimensions of chessboard\n",
    "        self.xdim, self.ydim = inner_dims\n",
    "\n",
    "        #--- object and image points used in findChessboardCorners()\n",
    "        self.objpoints = None\n",
    "        self.imgpoints = None\n",
    "        \n",
    "        #--- image of chessboard annotated with corners found\n",
    "        self.img_corners = None\n",
    "        \n",
    "        msg = 'Image loaded for {} with dims {}.'\n",
    "        self.logger.debug (msg.format(self.filename, (self.xdim, self.ydim)))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def findChessboardCorners(self):\n",
    "        '''\n",
    "        Finds the chessboard corners of the chessboard image.\n",
    "        \n",
    "        Returns:\n",
    "        - corners_found: the image space coordinates of the corners of the chessboard image.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #--- given the chessboard image and inner dimensions (xdim, ydim), find the chessboard corners \n",
    "        gray = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)\n",
    "        corners_found, corners = cv2.findChessboardCorners(gray, (self.xdim, self.ydim), flags=None)\n",
    "        \n",
    "        if corners_found:\n",
    "            #--- generate object points in the XY plane; Z=0\n",
    "            #--- dimensions will be based on the chessboard_images\n",
    "            #--- corners found are placed in an order from left to right, top to bottom\n",
    "            #--- thereforem object points are generated in column (X) priority order\n",
    "            #--- ref: https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html\n",
    "            #--- object_points should be: (0,0,0), (1,0,0), (2,0,0)..(xdim-1,0,0), (1,1,0)...\n",
    "            self.objpoints = np.zeros(shape=(self.xdim * self.ydim, 3), dtype=np.float32)\n",
    "            self.objpoints[:, :2] = np.array([(x, y) for y in range(self.ydim) for x in range(self.xdim)])\n",
    "            \n",
    "            #--- save corners found to imgpoints\n",
    "            self.imgpoints = corners\n",
    "            \n",
    "            #--- save image with corners annotated to img_corners\n",
    "            self.img_corners = np.copy (self.img)\n",
    "            self.img_corners = cv2.drawChessboardCorners(self.img_corners, (self.xdim, self.ydim), self.imgpoints, True)                 \n",
    "            \n",
    "            msg = \"Found corners for {}.\"\n",
    "            self.logger.debug (msg.format(self.filename))\n",
    "        else:\n",
    "\n",
    "            msg = \"DID NOT FIND corners for {}, dims: {}.\"\n",
    "            self.logger.warning (msg.format(self.filename, (self.xdims, self.ydims)))\n",
    "            \n",
    "        return corners_found\n",
    "    \n",
    "    \n",
    "class ChessboardCameraCalibrationSet:\n",
    "    '''\n",
    "    Distortion calibration set for Camera.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__: specifies path, filenames and inner square dimensions chessboard images.\n",
    "    - loadChessboardImages\n",
    "    - findChessboardCorners\n",
    "    - showCorners\n",
    "    - getCalibrationParams\n",
    "    - getChessboardImg\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.logger = logging.getLogger(\"ChessboardImages\")\n",
    "        \n",
    "        #--- chessboard image meta data (basepath, filenames with inner dims, image shape)\n",
    "        #--- base path to images\n",
    "        self.basepath = 'camera_cal/'\n",
    "        #--- image filenames with corresponding inner dimensions manually counted\n",
    "        self.filenames_dims = [\n",
    "            ('calibration1.jpg', (9,5)),\n",
    "            ('calibration2.jpg', (9,6)),\n",
    "            ('calibration3.jpg', (9,6)),\n",
    "            ('calibration4.jpg', (5,6)),  #--- close corners, watch it\n",
    "            ('calibration5.jpg', (7,6)),\n",
    "            ('calibration6.jpg', (9,6)),\n",
    "            ('calibration7.jpg', (9,6)),\n",
    "            ('calibration8.jpg', (9,6)),\n",
    "            ('calibration9.jpg', (9,6)),\n",
    "            ('calibration10.jpg', (9,6)),\n",
    "            ('calibration11.jpg', (9,6)),\n",
    "            ('calibration12.jpg', (9,6)),\n",
    "            ('calibration13.jpg', (9,6)),\n",
    "            ('calibration14.jpg', (9,6)),\n",
    "            ('calibration15.jpg', (9,6)),\n",
    "            ('calibration16.jpg', (9,6)),\n",
    "            ('calibration17.jpg', (9,6)),\n",
    "            ('calibration18.jpg', (9,6)),\n",
    "            ('calibration19.jpg', (9,6)),\n",
    "            ('calibration20.jpg', (9,6)),\n",
    "             ]\n",
    "        \n",
    "        #--- shape of all images in cols,rows; for later use in calibrate camera\n",
    "        self.image_shape = (1280, 720)\n",
    "        \n",
    "        #--- a list of data about the boards: (RGB image of board, XY inner dimensions, filename)\n",
    "        self.chessboard_images = []\n",
    "        \n",
    "        #--- objpoints and imgpoints used for camera calibration\n",
    "        #--- will be compiled in findChessboardCorners\n",
    "        self.objpoints = []\n",
    "        self.imgpoints = []\n",
    "        \n",
    "        return\n",
    "\n",
    "    def loadChessboardImages(self):\n",
    "        '''Loads chessboard images into self.chessboard_images; call before using find chessboard corners.'''\n",
    "        \n",
    "        msg = \"Loading chessboard images...\"\n",
    "        self.logger.info (msg)\n",
    "        \n",
    "        for filename_dim in self.filenames_dims:\n",
    "            \n",
    "            filename = filename_dim[0]\n",
    "            dims     = filename_dim[1]\n",
    "            \n",
    "            #--- read in files\n",
    "            chessboard_image = ChessboardImage (self.basepath, filename, dims)\n",
    "            self.chessboard_images.append(chessboard_image)\n",
    "            \n",
    "        msg = \"...completed loading chessboard images.\"\n",
    "        self.logger.info (msg)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def findChessboardCorners(self):\n",
    "        '''\n",
    "        Finds chessboard corners for each chessboard; call loadchessboardimages before this call.\n",
    "        \n",
    "        Notes:\n",
    "        - Calls each chessboard image to find corners\n",
    "        - Collects chessboard image objpoints and imgpoints to self.objpoints and self.imgpoints\n",
    "        '''\n",
    "\n",
    "        msg = \"Finding chessboard corners...\"\n",
    "        self.logger.info (msg)\n",
    "        \n",
    "        for chessboard_image in self.chessboard_images:\n",
    "            if chessboard_image.findChessboardCorners():\n",
    "                #--- imgpoints[i] corresponds to objpoints[i]\n",
    "                self.imgpoints.append (chessboard_image.imgpoints)\n",
    "                self.objpoints.append (chessboard_image.objpoints)\n",
    "            \n",
    "        msg = \"...completed finding chessboard corners.\"\n",
    "        self.logger.info (msg)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def getCalibrationParams(self):\n",
    "        '''\n",
    "        Returns the parameters needed to calibrate Camera.\n",
    "        \n",
    "        Returns:\n",
    "        - objpoints, imgpoints: objpoints and imgpoints generated from findChessboardCorners.\n",
    "        - image_shape: shape of image of chessboard images\n",
    "        \n",
    "        Notes:\n",
    "        - objpoints, imgpoints, image_shape will be used in camera calibration\n",
    "        '''\n",
    "        self.loadChessboardImages()\n",
    "        self.findChessboardCorners()\n",
    "        \n",
    "        return (self.objpoints, self.imgpoints, self.image_shape)\n",
    "    \n",
    "\n",
    "    def showCorners(self, ncols=1):\n",
    "        '''\n",
    "        Displays images of the chessboard with all chessboard corners annotated.\n",
    "        \n",
    "        Params:\n",
    "        - ncols: number of columns to fit all the images into.\n",
    "        '''\n",
    "        \n",
    "        nimgs = len(self.chessboard_images)\n",
    "        nrows = nimgs // ncols + (nimgs % ncols)\n",
    "        plt.figure(figsize=(16, 10 * (nrows + 1) // ncols))\n",
    "        for idx, chessboard_image in enumerate (self.chessboard_images):\n",
    "            ax = plt.subplot(nrows, ncols, idx + 1)\n",
    "            ax.imshow(chessboard_image.img_corners)\n",
    "            ax.set_title(chessboard_image.filename)\n",
    "        return\n",
    "    \n",
    "    def getChessboardImg(self, idx=0):\n",
    "        '''\n",
    "        Returns an image of a chessboard for inspection\n",
    "        \n",
    "        Params:\n",
    "        - idx: index of chessboard image to inspect\n",
    "        '''\n",
    "        \n",
    "        return self.chessboard_images[idx].img\n",
    "    \n",
    "\n",
    "class Camera:\n",
    "    '''\n",
    "    Creates image corrected for distortion.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - calibrateCamera: call before using undistort().\n",
    "    - undistort\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__ (self):\n",
    "        \n",
    "        self.logger = logging.getLogger(\"Camera\")\n",
    "        \n",
    "        #--- camera matrix\n",
    "        self.mtx = None\n",
    "        \n",
    "        #--- distortion coefficient\n",
    "        self.dist = None\n",
    "        \n",
    "        #--- image shape in X,Y (numcols, numrows)\n",
    "        self.image_shape = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    def calibrateCamera (self, calibration_set=None):\n",
    "        '''\n",
    "        Calculates the camera matrix and distortion coefficients used to correct distortion.\n",
    "        \n",
    "        Params:\n",
    "        - calibration_set: a class with a function called getCalibrationParams that returns\n",
    "        objpoints, imgpoints, and image_shape used for camera calibration\n",
    "        '''\n",
    "        \n",
    "        if calibration_set is None:\n",
    "            calibration_set = ChessboardCameraCalibrationSet()\n",
    "            \n",
    "        objpoints, imgpoints, self.image_shape = calibration_set.getCalibrationParams ()\n",
    "        \n",
    "        #--- rotation and translation vectors not used for this project\n",
    "        cal_found, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, self.image_shape, None, None)\n",
    "        \n",
    "        if cal_found:\n",
    "            msg = \"Camera calibrated.\"\n",
    "            self.logger.info(msg)            \n",
    "        else:\n",
    "            msg = \"Camera was not calibrated.\"\n",
    "            self.logger.warning(msg)            \n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def undistort(self, img):\n",
    "        '''\n",
    "        corrects image distortion\n",
    "        \n",
    "        Paramters:\n",
    "        - img: image to apply distortion correction\n",
    "        \n",
    "        Returns:\n",
    "        - img_undist: the undistorted image\n",
    "        \n",
    "        Notes:\n",
    "        - img_undist should then be fed to the LaneEnhancer \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        img_undist = cv2.undistort(img, self.mtx, self.dist)\n",
    "        \n",
    "        return img_undist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaneEnhancer\n",
    "- LaneEnhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enhancer:\n",
    "    '''\n",
    "    Enhances appearance of road lanes using edge detection and color channels.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - Sobel_x\n",
    "    - s_channel\n",
    "    - enhance: combine Sobel_x gradient and s_channel thresholding\n",
    "    '''\n",
    "    \n",
    "    def SobelX(self, img, t_min=20, t_max=255):\n",
    "        '''\n",
    "        Detects edges by measuring gradients along x axis.\n",
    "        \n",
    "        Params:\n",
    "        - img: an RGB image of road to enhance\n",
    "        - t_min, t_max: thresholds for gradient along x axis to trigger edge detection\n",
    "        \n",
    "        Returns:\n",
    "        - mask: a binary image highlighting where edges were detected\n",
    "        '''\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, dx=1, dy=0))\n",
    "        sobel_scaled = np.uint8(255 * sobel / np.max(sobel))\n",
    "        \n",
    "        mask = np.zeros_like(sobel_scaled)\n",
    "        \n",
    "        #--- activate (set to \"1\") all pixels that meet the x gradient thresholds\n",
    "        mask[(t_min <= sobel_scaled) & (sobel_scaled <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def SChannel (self, img, t_min=96, t_max=255):\n",
    "        '''\n",
    "        Detects pixels meeting s_channel thresholds.\n",
    "        \n",
    "        Params:\n",
    "        - img: an RGB image of road to enhance\n",
    "        - t_min, t_max: thresholds for s_channel detection; default threshold values\n",
    "        were manually chosen for enhancing yellow and white pixels of road lanes\n",
    "        \n",
    "        Returns:\n",
    "        - mask: a binary image highlighting where pixels met the s_channel threshold \n",
    "        for yellow and white colors\n",
    "        '''\n",
    "        \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        \n",
    "        #--- extract the s_channel frol hls\n",
    "        s_channel = hls[:,:,2]\n",
    "        \n",
    "        mask = np.zeros_like(s_channel)\n",
    "        \n",
    "        #--- activate all pixels that meet the s-channel threshold\n",
    "        mask[(t_min <= s_channel) & (s_channel <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def LChannel (self, img, t_min=200, t_max=255):\n",
    "        '''\n",
    "        Detects pixels meeting s_channel thresholds.\n",
    "        \n",
    "        Params:\n",
    "        - img: an RGB image of road to enhance\n",
    "        - t_min, t_max: thresholds for s_channel detection; default threshold values\n",
    "        were manually chosen for enhancing yellow and white pixels of road lanes\n",
    "        \n",
    "        Returns:\n",
    "        - mask: a binary image highlighting where pixels met the s_channel threshold \n",
    "        for yellow and white colors\n",
    "        '''\n",
    "        \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        \n",
    "        #--- extract the l_channel frol hls\n",
    "        l_channel = hls[:,:,1]\n",
    "        \n",
    "        mask = np.zeros_like(l_channel)\n",
    "        \n",
    "        #--- activate all pixels that meet the s-channel threshold\n",
    "        mask[(t_min <= l_channel) & (l_channel <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    \n",
    "    def enhance(self, img):\n",
    "        '''\n",
    "        Combines SobelX and SChannel methods for enhancing lanes\n",
    "        \n",
    "        Params:\n",
    "        - img: an RGB image of road to enhance\n",
    "\n",
    "        Returns:\n",
    "        - a binary image resulting from bitwise \"or\" of sobel and s-channel masks\n",
    "        '''\n",
    "        \n",
    "        sobel_mask     = self.SobelX (img)\n",
    "        s_channel_mask = self.SChannel(img)\n",
    "        l_channel_mask = self.LChannel(img)\n",
    "        \n",
    "        # return sobel_mask | s_channel_mask    \n",
    "    \n",
    "        return s_channel_mask | l_channel_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warper Module\n",
    "- TopDownWarperCalibrationSet\n",
    "- ImageWarper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopDownWarperCalibrationSet:\n",
    "    '''\n",
    "    Data for calculating transformation matrix for an ImageWarper\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - showPoints\n",
    "    \n",
    "    Notes:\n",
    "    - Persective transforms using this calibration set result in a top-down view\n",
    "    - This is the default calibration set for ImageWarper\n",
    "    '''    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #--- save image calibration points were based off of\n",
    "        self.img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "        \n",
    "        #--- src and dst points for perspective transformations\n",
    "        #--- coordinages were derived from manual measurement\n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451],  [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[291,   0], [1023,   0], [1023, 719], [291, 719]])\n",
    "        \n",
    "        '''\n",
    "        Older src and dest points that worked but not as good as final\n",
    "        \n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451], [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[191,   0], [1123,  0], [1123, 719], [211, 719]])\n",
    "        \n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451], [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[391,   0], [923,   0], [923,  719], [391, 719]])\n",
    "        '''\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def showPoints(self):\n",
    "        '''\n",
    "        plots src and dst points on image calibration points were based off of\n",
    "        '''\n",
    "        \n",
    "        plt.figure(figsize=(11, 6.5))\n",
    "\n",
    "        ax = plt.sublot(121)\n",
    "        for i in range(4):\n",
    "            ax.plot(src_points[i][0], src_points[i][1], '.')\n",
    "        return\n",
    "        ax.imshow(self.img)\n",
    "        \n",
    "        ax = plt.sublot(122)\n",
    "        for i in range(4):\n",
    "            ax.plot(dst_points[i][0], dst_points[i][1], '.')\n",
    "        return\n",
    "        ax.imshow(self.img)\n",
    "\n",
    "        \n",
    "class ImageWarper:\n",
    "    '''\n",
    "    Warps and dewarps images.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__()\n",
    "    - warpPerspective()\n",
    "    - unWarpPerspective()\n",
    "\n",
    "    Notes:\n",
    "    -  transforms (warps) an image for use by a LaneDetector\n",
    "    '''\n",
    "\n",
    "    def __init__(self, calibration_set=None):\n",
    "        '''\n",
    "        Calculates the transform and inverse tranformation matrices\n",
    "        \n",
    "        Params:\n",
    "        - calibration set: set of src are dst points of the form [[x1, y2], [x2, y2], ...];\n",
    "        src points are points on original image; dst points are points that the src points\n",
    "        will be transformed to\n",
    "        '''\n",
    "        \n",
    "        #--- set default calibration set to top-down perspective\n",
    "        if calibration_set is None:\n",
    "            calibration_set = TopDownWarperCalibrationSet()\n",
    "        \n",
    "        #--- M: transformation matrix\n",
    "        self.M = cv2.getPerspectiveTransform(calibration_set.src_points, \n",
    "                                             calibration_set.dst_points)\n",
    "        \n",
    "        #--- use invM when unwarping image\n",
    "        self.invM = cv2.getPerspectiveTransform(calibration_set.dst_points, \n",
    "                                                calibration_set.src_points)\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def warpPerspective(self, img):\n",
    "        '''\n",
    "        warps perspective based on transformation_matrix\n",
    "        \n",
    "        Params:\n",
    "        - img: the image to be distorted; can be RGB or gray scale\n",
    "        \n",
    "        Returns:\n",
    "        - img_warped: the image with the per\n",
    "        \n",
    "        Notes:\n",
    "        - Undistort img with an camera instance before warping\n",
    "        '''\n",
    "        \n",
    "        img_warped = cv2.warpPerspective(img, self.M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return img_warped\n",
    "    \n",
    "    def unwarpPerspective(self, img):\n",
    "        \n",
    "        img_unwarped = cv2.warpPerspective(img, self.invM, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return img_unwarped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaneLineGenerator\n",
    "- SlidingWindow\n",
    "- LinearWindow\n",
    "- Line\n",
    "- LaneLineFinder\n",
    "- LeftLaneFinder\n",
    "- RightLaneFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- image to real space scaling default per lesson Measuring Curvature II\n",
    "#--- in meters per pixel; used in calculating radius of curvature\n",
    "#--- as well as offset center\n",
    "XM_PER_PIXEL = 3.7 / 700    \n",
    "YM_PER_PIXEL = 30 / 720\n",
    "    \n",
    "class Line:\n",
    "    '''\n",
    "    A line representing a lane on the road.\n",
    "\n",
    "    Methods:\n",
    "    - __init__\n",
    "    - fit\n",
    "    - radius: calucaltes radius of curvature\n",
    "    - generatePoints\n",
    "    - getPaintPoints\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.logger = logging.getLogger(\"Line \" + str(id(self))[-4:])\n",
    "\n",
    "        #--- coefficients of line where x = ay**2 + by + c\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "        \n",
    "        #--- list of coefficients of previously found lines\n",
    "        self.prev_coeffs = []        #--- [[a1, b2, c1], [a2, b2, c2], ...]\n",
    "        self.max_coeffs = 30    #--- max coeffs to keep before popping oldest coeff\n",
    "\n",
    "\n",
    "        #--- True if polyfit() solved for line coefficients\n",
    "        #--- check this variable first before using Line\n",
    "        self.found = False\n",
    "        \n",
    "        #--- numpy array of points representing the line\n",
    "        #--- these will be generated in call to generateXY\n",
    "        self.x = None\n",
    "        self.y = None    #--- should be [(height of image - 1) to 0]\n",
    "\n",
    "        #--- pts() method combines x and y to form [[x1, y1], [x2, y2], ...]\n",
    "        #--- used in draw functions\n",
    "        self.pts = None    \n",
    "\n",
    "        return\n",
    "        \n",
    "    def fit(self, x_points, y_points, polyfit_tries=3):\n",
    "        '''\n",
    "        Sets the coefficients of the line through polyfit.\n",
    "        \n",
    "        Params:\n",
    "        - x, y: coordinates of points to fit line\n",
    "        - real_world: bool. true if trying to fit real world coordinates from image space; used to \n",
    "        support calculating radius of curvature in radius(); we should not have to use this since \n",
    "        we will try to use the scaling algorithm in \"Measuring Curvature II\"\n",
    "        for the coefficients in call to radius()\n",
    "        - polyfit_tries: number of attempts to polyfit before continuing\n",
    "        \n",
    "        Notes:\n",
    "        - Makes up to default 10 attempts with error checking for a successful fit.\n",
    "        - Coefficients are set to none if no line found\n",
    "        - Needed to use error handling for calls to polyfit; would cause \"SVD did not \n",
    "        converge\" error in jupyter notebook every other run; polyfit will likely succeed on second try\n",
    "        - Discussion of SVD error: https://github.com/numpy/numpy/issues/16744 says its due to windows\n",
    "        '''\n",
    "        \n",
    "        self.pts = None    \n",
    "        self.x = None\n",
    "        self.y = None    #--- should be [0 to (height of image - 1)]\n",
    "        \n",
    "        self.found = False         # true if polyfit succesfully fits the line\n",
    "        tries = 0\n",
    "        while tries < polyfit_tries and not self.found:\n",
    "            tries += 1\n",
    "            try:\n",
    "                #--- we solve for X!!! i.e. x = ay**2 + by + c\n",
    "                fit = np.polyfit(y_points, x_points, deg=2)\n",
    "                if tries > 1:\n",
    "                    msg = \"Polyfit succeeded on try {}.\"\n",
    "                    self.logger.warning(msg.format(tries))\n",
    "                self.found = True\n",
    "            \n",
    "            except Exception as e:\n",
    "                if tries < polyfit_tries:\n",
    "                    msg = \"Polyfit failed: {}. Trying again.\"\n",
    "                    self.logger.warning(msg.format(e))\n",
    "                else:\n",
    "                    msg = \"Polyfit failed to fit a line. {}.\"\n",
    "                    self.logger.warning(msg.format(e))\n",
    "                    \n",
    "        if self.found:\n",
    "            self.a = fit[0]    # coeff for y**2\n",
    "            self.b = fit[1]    # coeff for y\n",
    "            self.c = fit[2]    # constant\n",
    "        else:\n",
    "            self.a = None\n",
    "            self.b = None\n",
    "            self.c = None\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def smooth_new (self, N=3):\n",
    "        '''\n",
    "        Smooths the line by using the average of past coeefficients\n",
    "        \n",
    "        Params:\n",
    "        - N: number of standard deviations from mean coeff value to start smoothing\n",
    "        \n",
    "        Returns:\n",
    "        - self.found: True if a line was found previously in fit and was a good line, or if \n",
    "        fit did not find a line by smooth was able to use the average of past coeffs to define \n",
    "        a line\n",
    "        \n",
    "        Notes:\n",
    "        - Call after fit!\n",
    "        - if fit() did not find a line, smooth() can set coeffs to average of coeffs for line!\n",
    "        thus, finding a line, though it's an average of previous\n",
    "        \n",
    "        - Checks if x is within m std devs of the mean of values in arr\n",
    "        - see ref below for discussion of outlier\n",
    "        - ref: https://docs.oracle.com/cd/E17236_01/epm.1112/cb_statistical/frameset.htm?ch07s02s10s01.html\n",
    "        '''\n",
    "        \n",
    "        if self.prev_coeffs:\n",
    "            \n",
    "            avg_prev_coeffs = np.average(self.prev_coeffs, axis=0)\n",
    "            \n",
    "            if self.found:\n",
    "                \n",
    "                if len (avg_prev_coeffs) > 10\n",
    "                    #--- see if coeff of line is within std devs of avg of previous lines \n",
    "                    std_prev_coeffs = np.std(self.prev_coeffs, axis=0)\n",
    "                    in_range = abs(self.x - avg_prev_coeffs) < N*std_prev_coeffs\n",
    "                else:\n",
    "                    in_range = abs(self.x - avg_prev_coeffs) < 50\n",
    "\n",
    "                if not all(in_range):\n",
    "                    #--- line is an outlier; smooth it as an average of previous lines\n",
    "                    self.x = avg_prev_coeffs\n",
    "                    \n",
    "                    # self.a, self.b, self.c = np.average (np.vstack((avg_prev_coeffs, np.array([self.a, self.b, self.c]))),                                                         axis = 0)\n",
    "                else:\n",
    "                    msg = \"Line is good! No need to average.\"\n",
    "                    self.logger.debug(msg)\n",
    "                    \n",
    "                self.prev_coeffs.append([self.a, self.b, self.c]) \n",
    "\n",
    "                if len(self.prev_coeffs) > self.max_coeffs:\n",
    "                    #--- pop first to remove oldest line from list to prevent being include in average\n",
    "                    self.prev_coeffs.pop(0)\n",
    "                    msg = \"Coeff buffer full. Removed oldest line. Buffer size: {}.\"\n",
    "                    self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "                    \n",
    "            else:\n",
    "                #--- line not found, use average of previous coffecients now for the line\n",
    "                msg = \"Line was not found! Using averages of old lines.\"\n",
    "                self.logger.debug(msg)\n",
    "                \n",
    "                self.a, self.b, self.c = avg_prev_coeffs                \n",
    "                \n",
    "                #--- pop first coeff in list to prevents using older coeffs again\n",
    "                #--- eventually, list decays to nothing if no lines are found\n",
    "                #--- forcing to not use old information\n",
    "                self.prev_coeffs.pop(0)\n",
    "                \n",
    "                #--- set found to True since we \"found\" a line \n",
    "                #--- using the average of previous coeffs\n",
    "                self.found = True\n",
    "                \n",
    "        elif self.found:\n",
    "            #--- first coeff to add to list! \n",
    "            #--- don't smooth since there is nothing to smooth to\n",
    "            self.prev_coeffs.append([self.a, self.b, self.c]) \n",
    "            \n",
    "        msg = \"Number of old lines/coeffs: {}.\"\n",
    "        self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "            \n",
    "        return self.found\n",
    "    \n",
    "    \n",
    "    def smooth(self, N=3):\n",
    "        '''\n",
    "        Smooths the line by using the average of past coeefficients\n",
    "        \n",
    "        Params:\n",
    "        - N: number of standard deviations from mean coeff value to start smoothing\n",
    "        \n",
    "        Returns:\n",
    "        - self.found: True if a line was found previously in fit and was a good line, or if \n",
    "        fit did not find a line by smooth was able to use the average of past coeffs to define \n",
    "        a line\n",
    "        \n",
    "        Notes:\n",
    "        - Call after fit!\n",
    "        - if fit() did not find a line, smooth() can set coeffs to average of coeffs for line!\n",
    "        thus, finding a line, though it's an average of previous\n",
    "        \n",
    "        - Checks if x is within m std devs of the mean of values in arr\n",
    "        - see ref below for discussion of outlier\n",
    "        - ref: https://docs.oracle.com/cd/E17236_01/epm.1112/cb_statistical/frameset.htm?ch07s02s10s01.html\n",
    "        '''\n",
    "        \n",
    "        if self.prev_coeffs:\n",
    "            \n",
    "            avg_prev_coeffs = np.average(self.prev_coeffs, axis=0)\n",
    "            \n",
    "            if self.found:\n",
    "                \n",
    "                #--- see if coeff of line is within std devs of avg of previous lines \n",
    "                coeff = np.array([self.a, self.b, self.c])\n",
    "                std_prev_coeffs = np.std(self.prev_coeffs, axis=0)\n",
    "                in_range = abs(coeff - avg_prev_coeffs) < N*std_prev_coeffs\n",
    "\n",
    "                if not all(in_range):\n",
    "                    #--- line is an outlier; smooth it as an average of previous lines\n",
    "                    msg = \"Line is an outlier! Using averages of old lines.\"\n",
    "                    self.logger.debug(msg)\n",
    "                    \n",
    "                    msg = \"Curr coeffs {}, {}, {}\"\n",
    "                    self.logger.debug(msg.format(self.a, self.b, self.c))\n",
    "\n",
    "                    msg = \"Avg coeffs: {}, {}, {}\"\n",
    "                    self.logger.debug(msg.format(avg_prev_coeffs[0], avg_prev_coeffs[1], avg_prev_coeffs[2]))\n",
    "                    \n",
    "                    self.a, self.b, self.c = np.average (\n",
    "                        np.vstack((avg_prev_coeffs, np.array([self.a, self.b, self.c]))),\n",
    "                        axis = 0\n",
    "                    )\n",
    "                else:\n",
    "                    msg = \"Line is good! No need to average.\"\n",
    "                    self.logger.debug(msg)\n",
    "                    \n",
    "                self.prev_coeffs.append([self.a, self.b, self.c]) \n",
    "\n",
    "                if len(self.prev_coeffs) > self.max_coeffs:\n",
    "                    #--- pop first to remove oldest line from list to prevent being include in average\n",
    "                    self.prev_coeffs.pop(0)\n",
    "                    msg = \"Coeff buffer full. Removed oldest line. Buffer size: {}.\"\n",
    "                    self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "                    \n",
    "            else:\n",
    "                #--- line not found, use average of previous coffecients now for the line\n",
    "                msg = \"Line was not found! Using averages of old lines.\"\n",
    "                self.logger.debug(msg)\n",
    "                \n",
    "                self.a, self.b, self.c = avg_prev_coeffs                \n",
    "                \n",
    "                #--- pop first coeff in list to prevents using older coeffs again\n",
    "                #--- eventually, list decays to nothing if no lines are found\n",
    "                #--- forcing to not use old information\n",
    "                self.prev_coeffs.pop(0)\n",
    "                \n",
    "                #--- set found to True since we \"found\" a line \n",
    "                #--- using the average of previous coeffs\n",
    "                self.found = True\n",
    "                \n",
    "        elif self.found:\n",
    "            #--- first coeff to add to list! \n",
    "            #--- don't smooth since there is nothing to smooth to\n",
    "            self.prev_coeffs.append([self.a, self.b, self.c]) \n",
    "            \n",
    "        msg = \"Number of old lines/coeffs: {}.\"\n",
    "        self.logger.debug(msg.format(len(self.prev_coeffs)))\n",
    "            \n",
    "        return self.found\n",
    "    \n",
    "    def generateXY(self, img_ht):\n",
    "        '''\n",
    "        Generates the x and y coordinates of the line along the height of the image.\n",
    "        \n",
    "        Params:\n",
    "        - img_ht: height of image\n",
    "        \n",
    "        Notes:\n",
    "        - Call smooth() before calling this function!  M--- wait\n",
    "        - Updates x_points; array of the x coordinates of the line in int32, none if line was not found\n",
    "        - Updatesm y_points; array of y coordinates of the line in int32, none if line was not found;\n",
    "        y points should be from 0 to img_ht - 1\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return\n",
    "\n",
    "        #--- Check if we have already generated lines for this height\n",
    "        #--- if we havent, generate the points else skip and just reuse what we have already\n",
    "        #--- generate y points from 0 to img_ht - 1, cast to int32 for ease of plotting\n",
    "        self.y = np.int32 (np.array([y for y in range(img_ht)]))\n",
    "\n",
    "        #--- calculate points based on x, cast to int32 for ease of plotting\n",
    "        self.x = np.int32 (self.a * self.y**2 + self.b * self.y + self.c)\n",
    "\n",
    "        msg = \"Generated points for ht {}.\"\n",
    "        self.logger.debug(msg.format(img_ht))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def lookupX(self, y):\n",
    "        '''\n",
    "        Looks up x-coordinate of line given y-coordinate of line\n",
    "        \n",
    "        Params:\n",
    "        - y: an array of y values \n",
    "        \n",
    "        Returns:\n",
    "        - x: an array of corresponding x values found by looking up in self.x\n",
    "        \n",
    "        Notes:\n",
    "        - Call generateXY() before calling this\n",
    "        - Assumes 0 <= y < self.x.size; does not check if y is a valid index!!!\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return None\n",
    "        \n",
    "        return self.x[y]\n",
    "    \n",
    "    def radius(self, y, xm_per_pix=None, ym_per_pix=None):\n",
    "        '''\n",
    "        Returns real world radius of curvature at y.\n",
    "        \n",
    "        Params:\n",
    "        - y: y-position in image space; this should be bottom of image; do not convert\n",
    "        to real world meters; conversion to real world coords is done in function\n",
    "        - real_world: bool. true if trying to fit real world coordinates from image space\n",
    "        - ym_per_pix: numer of meters per pixel along y axis; only used if real_world is True\n",
    "        \n",
    "        Returns: \n",
    "        - R: radius in pixels, or in meters if real_world is True; None if exception\n",
    "        \n",
    "        Notes:\n",
    "        - Call fit() before this function!\n",
    "        - We use formula in the lesson Measuring Curvature II of Lesson 8:\n",
    "        \"For example, if the parabola is x= a*(y**2) +b*y+c; and mx and my are the scale \n",
    "        for the x and y axis, respectively (in meters/pixel); then the scaled parabola is \n",
    "        x= mx / (my ** 2) *a*(y**2)+(mx/my)*b*y+c\"; \n",
    "        I thinks it's x= mx / (my ** 2) *a*(y**2)+(mx/my)*b*y+mx*c; anyway so:\n",
    "           \n",
    "           real_a = a * mx / my**2 \n",
    "           \n",
    "           real_b = b * mx / my\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            #--- rescale coeffs and y to real world\n",
    "            a = self.a * xm_per_pix / ym_per_pix**2\n",
    "            b = self.b * xm_per_pix / ym_per_pix\n",
    "            y = y * ym_per_pix    # scale y to real-world!\n",
    "            R = (1 + (2*a*y + b)**2)**(3/2) / abs(2*a)\n",
    "            msg = \"Radius of curvature: {}.\"\n",
    "            self.logger.debug(msg.format(R))\n",
    "            \n",
    "        except Exception as e:\n",
    "            msg = \"Error in calculating radius of curvature: {}.\"\n",
    "            self.logger.warning(msg.format(e))\n",
    "            R = None\n",
    "        \n",
    "        return R\n",
    "        \n",
    "    def baseX(self):\n",
    "        '''\n",
    "        Returns the x coordinate of the \"base\" of the line; i.e. at the bottom of image.\n",
    "        \n",
    "        Notes:\n",
    "        - Used in calculating offset from center for the lane finder\n",
    "        - Call generateXY() before calling this\n",
    "        - returns none if no line was found\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return None\n",
    "            \n",
    "        return self.x[-1]\n",
    "    \n",
    "    def getPoints(self):\n",
    "        '''\n",
    "        Returns an array of points repesenting the line of the lane for use in cv2 draw functions.\n",
    "        \n",
    "        Returns:\n",
    "        - an array of points like [[[x1, y1], [x2, y2], ...]], shape is like (1, numpoints, 2).\n",
    "\n",
    "        Notes:\n",
    "        - Call generateXY() before calling this function\n",
    "        - Points are suitable for using in cv2 draw functions\n",
    "        - If no lanes were found, returns None\n",
    "        - Order of points is from y=0 to number of points\n",
    "        '''\n",
    "        \n",
    "        if not self.found:\n",
    "            return None\n",
    "            \n",
    "        if self.pts is None:\n",
    "            #--- combine and transform x_ and y_points to [[x1, y1], [x2, y2], ...]\n",
    "            #--- vstack shape=(2, n), then after transpose shape=(n,2)\n",
    "            self.pts = np.array([(np.transpose(np.vstack((self.x, self.y))))])\n",
    "            msg = \"New pts calculated.\"\n",
    "            self.logger.debug(msg)\n",
    "        else:\n",
    "            msg = \"Reusing pts.\"\n",
    "            self.logger.debug(msg)\n",
    "        return self.pts\n",
    "        \n",
    "    def paint(self, img):\n",
    "        '''\n",
    "        Paints line on img.\n",
    "        '''\n",
    "        if self.found:\n",
    "            cv2.polylines(img, \n",
    "                          pts       = self.getPoints(), \n",
    "                          isClosed  = False, \n",
    "                          color     = [255, 0, 0],    #--- default red line color\n",
    "                          thickness = 20)\n",
    "        return\n",
    "\n",
    "\n",
    "class SlidingWindow:\n",
    "    '''\n",
    "    Finds lane line points using a sliding window search area.\n",
    "\n",
    "    Methods:\n",
    "    - __init__\n",
    "    - reinit: reinitializes variables so instance can be reused\n",
    "    - \n",
    "\n",
    "    Notes:\n",
    "    - Lane line points are points on the image that belong to a lane in the road\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, x_mid, target_ht, image_points, \n",
    "                 num_segments = 8, x_offset=100, numpoints_found_thresh = 50):\n",
    "\n",
    "        #--- x1 = x_mid - offset, x2 = x_mid + offset\n",
    "        self.x_mid    = x_mid\n",
    "        self.x_offset = x_offset\n",
    "        self.x1       = x_mid - x_offset\n",
    "        self.x2       = x_mid + x_offset\n",
    "        \n",
    "        self.ht = target_ht // num_segments\n",
    "        self.y2 = target_ht   #--- y2 is bottom of image\n",
    "        self.y1 = self.y2 - self.ht\n",
    "        \n",
    "        #--- number of points found to calculate\n",
    "        #--- average x for next mid point when window slides up\n",
    "        self.numpoints_found_thresh = numpoints_found_thresh\n",
    "        \n",
    "        #--- unpack image points which are all the nonzero points in target image\n",
    "        #--- point (image_points_x[i], image_points_y[i]) is a nonzero point in target image\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        #--- true if window has slid passed the top of the target image\n",
    "        self.passed_top = False\n",
    "        \n",
    "        #--- holds all image points found in current window using find_points\n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        #--- holds coordinates of windows borders as it is slid up\n",
    "        #--- used for demo\n",
    "        self.window_history = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def reinit (self, x_mid, target_ht, image_points, \n",
    "                 num_segments = 8, x_offset=100, numpoints_found_thresh = 50):\n",
    "        '''\n",
    "        Reinitializes the variables to reuse the instace. Simply calls __init__.\n",
    "        '''\n",
    "        \n",
    "        self.__init__(x_mid, target_ht, image_points, \n",
    "                 num_segments, x_offset, numpoints_found_thresh)\n",
    "        return\n",
    "    \n",
    "    def findPoints(self):\n",
    "        '''\n",
    "        Finds points in image_points that are in window.\n",
    "        \n",
    "        Returns:\n",
    "        - (lane_points_x, lane_points_y): a tuple of all the x points and y points of the image\n",
    "        that belong to the lane; so that the following is a point in the image \n",
    "        that belongs to the lane (lane_points_x[i], lane_points_y[i]); the points can then be used\n",
    "        in poly_fit to estimate the lane line (i.e. polyfit (y_lane_points, x_lane_points))\n",
    "        \n",
    "        Notes:\n",
    "        - Accumulates points found in lane_points_x and _y\n",
    "        - Calls slideUp() at the end to prepare the window to detect the next set of points\n",
    "        - mid_x updated to average if the number of points found exceed threshold\n",
    "        '''\n",
    "        \n",
    "        while not self.passed_top:        \n",
    "            \n",
    "            self.window_history.append([self.x1, self.y1, self.x2, self.y2])\n",
    "            \n",
    "            #--- mask in all points within window by x and y values\n",
    "            x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "            y_bool_mask = (self.y1 <= self.image_points_y) & (self.image_points_y <= self.y2)\n",
    "\n",
    "            #--- bit wise the x and y masks to get the actual points\n",
    "            xy_bool_mask = (x_bool_mask) & (y_bool_mask)\n",
    "\n",
    "            #--- apply mask to image_points_x and _y to find the points that are in window region\n",
    "            points_found_x = self.image_points_x[xy_bool_mask]\n",
    "            points_found_y = self.image_points_y[xy_bool_mask]\n",
    "\n",
    "            #--- collect the points found into lane_points_x and _y\n",
    "            #--- if window is not slid up after call to findpoints, \n",
    "            #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "            self.lane_points_x.extend(points_found_x)\n",
    "            self.lane_points_y.extend(points_found_y)\n",
    "\n",
    "            #--- update the midpoint if enough points found above threshold\n",
    "            if len(points_found_x) >= self.numpoints_found_thresh:\n",
    "                #--- must be INT! or \n",
    "                self.x_mid = np.int(np.average(points_found_x))\n",
    "                \n",
    "            self.slideUp()\n",
    "        \n",
    "        return (self.lane_points_x, self.lane_points_y)\n",
    "    \n",
    "    def slideUp (self):\n",
    "        '''\n",
    "        Updates window position by decreasing y1 and y2\n",
    "        \n",
    "        - y2 updated first to one line above y1\n",
    "        - y1 is then updated to y2 - height of window\n",
    "        - if y2 <= 0, then window has reached the top\n",
    "        - x1 and x2 are updated in case find_points updated xmid\n",
    "        '''\n",
    "        \n",
    "        #--- update y2 (bottom) of window to line above top\n",
    "        self.y2 = self.y1 - 1\n",
    "        \n",
    "        if self.y2 > 0:\n",
    "            self.y1 = self.y1 - self.ht - 1\n",
    "            if self.y1 < 0:\n",
    "                #--- set y1 to 0 if y1 is below 0\n",
    "                self.y1 = 0\n",
    "\n",
    "            self.x1 = self.x_mid - self.x_offset\n",
    "            self.x2 = self.x_mid + self.x_offset\n",
    "\n",
    "        else:\n",
    "            self.passed_top = True\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "class LinearWindow:\n",
    "    '''\n",
    "    Find points of a road lane in an image that are within a certain offset of a line.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - reinit\n",
    "    - findpoints\n",
    "    \n",
    "    Notes:\n",
    "    - A lane line found in a previous frame by SlidingWindow or LinearWindow is used\n",
    "    to start the search.\n",
    "    '''\n",
    "    \n",
    "    def __init__ (self, line, target_ht, image_points, x_offset=100):\n",
    "        '''\n",
    "        Defines the boarders of the linear search area along line.\n",
    "        \n",
    "        Params:\n",
    "        - line: a line found a previous frame of the road\n",
    "        - target_ht: height of the road image being examined\n",
    "        - image_points: all nonzero points of the image if the form [[x1, x2, ...], [y1, y2, ...]]\n",
    "        - x_offset: the offset along the x-axis of line to determine search area\n",
    "        '''\n",
    "        \n",
    "        self.line = line\n",
    "        self.ht = target_ht\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        #--- x1 and x2 define the borders/extents of the search area about the line\n",
    "        #--- use line.X() to generate the x points of the border\n",
    "        self.x1 = line.lookupX(self.image_points_y) - x_offset\n",
    "        #--- add offset twice to x1 to get right border of the search area\n",
    "        self.x2 = self.x1 + x_offset + x_offset\n",
    "        \n",
    "        #--- lane points have not been found yet\n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def reinit (self, line, target_ht, image_points, x_offset=100):\n",
    "        '''Reinitializes to reuse instance.'''\n",
    "        \n",
    "        self.__init__(line, target_ht, image_points, x_offset)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def findPoints (self):\n",
    "        '''\n",
    "        Collects all the points of the image within the linear border.\n",
    "        \n",
    "        Returns:\n",
    "        - lane_points_x, lane_points_y: points on the road image that are part of the lane;\n",
    "        these lane points are of the for [x1, x2, ...] and [y1, y2, ...] and are\n",
    "        fed to polyfit to determine the line that fits the area define by the lane points.\n",
    "        '''\n",
    "        \n",
    "        #--- mask in all points within linear window by x values\n",
    "        x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "        \n",
    "        #--- apply mask to image_points_x and _y to find the points \n",
    "        #--- that are in linear window search area \n",
    "        points_found_x = self.image_points_x[x_bool_mask]\n",
    "        points_found_y = self.image_points_y[x_bool_mask]\n",
    "        \n",
    "        #--- collect the points found into lane_points_x and _y\n",
    "        #--- if window is not slid up after call to findpoints, \n",
    "        #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "        self.lane_points_x.extend(points_found_x)\n",
    "        self.lane_points_y.extend(points_found_y)\n",
    "        \n",
    "        return self.lane_points_x, self.lane_points_y\n",
    "    \n",
    "\n",
    "class LaneLineFinder:\n",
    "    \"\"\"\n",
    "    Finds a line representing the lane of a road.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - updateXStart: need to implement in Child Class\n",
    "    - findImagePoints\n",
    "    - getSlidingWindow\n",
    "    - getLinearWindow\n",
    "    - selectLanePointsFinder\n",
    "    - checkLaneLine\n",
    "    - getPaintPoints\n",
    "    - paint\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size=180):\n",
    "        '''\n",
    "        Initlalizes LaneLineFinder.\n",
    "        \n",
    "        Params:\n",
    "        - buffer_size: number of a, b, c line-coefficients to keep; default to 180 \n",
    "        for 3 secs of video assuming 60fps; 6 secs of video if 30fps\n",
    "        '''\n",
    "        \n",
    "        self.logger = logging.getLogger(\"LaneLineFinder \" + str(id(self))[-4:])\n",
    "        \n",
    "        #--- topdown image of the road in binary format; should be fed in from ImageWarper\n",
    "        self.binary_warped = None\n",
    "        \n",
    "        #--- x value where sliding window starts its search\n",
    "        self.x_start       = None\n",
    "        \n",
    "        #--- nonzero points of road image\n",
    "        self.image_points  = None\n",
    "        \n",
    "        #--- holds lane line used to manage math of the line\n",
    "        self.lane_line = Line()\n",
    "        \n",
    "        #--- variables for the lane search methods\n",
    "        self.sliding_window     = None \n",
    "        self.linear_window      = None\n",
    "        self.lane_points_finder = None    #--- will eirher be sliding_window or linear_window\n",
    "        \n",
    "        #--- helps to select lane points search algorithm \n",
    "        self.use_linear_window  = False    #--- If true, use linear search window method, else use sliding\n",
    "        \n",
    "        #--- holds buffer the coefficients of the last buffer_size lines\n",
    "        #--- used for averaging out lines and other metrics\n",
    "        self.buffer_size = buffer_size     #--- number of measurements to hold in each array\n",
    "        self.a = np.array([])\n",
    "        self.b = np.array([])\n",
    "        self.c = np.array([])\n",
    "        \n",
    "        #--- points of the lane line in ([[x1, y1], [x2, y2], ...) format that is used in cv2 drawing functions\n",
    "        self.paint_points = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateXStart(self):\n",
    "        '''\n",
    "        Set that value of x_start used to begin the search using slidingWindow.\n",
    "        \n",
    "        Note:\n",
    "        - The method for setting the x_start depends on left or right sidedness of lane;\n",
    "        it should be implemented in the child class\n",
    "        '''\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def findImagePoints(self):\n",
    "        '''\n",
    "        Find all nonzero points on the image\n",
    "        \n",
    "        Returns:\n",
    "        - image_points_x, image_points_y: the x and y coordinates of all the nonzero points of the image;\n",
    "        the LaneFinder will search through these coordinates to find the points that are part of the lane\n",
    "        '''\n",
    "        \n",
    "        nonzero_points = np.nonzero(self.binary_warped)\n",
    "        \n",
    "        #--- y (row) points come first!!! index 0\n",
    "        #--- x (col) points are in second!!! index 1\n",
    "        image_points_y = np.array(nonzero_points[0])\n",
    "        image_points_x = np.array(nonzero_points[1])\n",
    "        \n",
    "        self.image_points = (image_points_x, image_points_y)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def getSlidingWindow(self):\n",
    "        '''\n",
    "        Returns a sliding window used to search image_points for the points of the lane.\n",
    "        \n",
    "        Returns:\n",
    "        - sliding_window\n",
    "        \n",
    "        Notes:\n",
    "        - If a sliding window instance already exists, it is reinitialized and reused.\n",
    "        - The starting X position must always be calculated and set for the sliding window.\n",
    "        '''\n",
    "\n",
    "        self.updateXStart()\n",
    "        if self.sliding_window:\n",
    "            #--- resuse existing and reinitizalize instance\n",
    "            self.sliding_window.reinit(self.x_start,\n",
    "                                      target_ht    = self.binary_warped.shape[0],\n",
    "                                      image_points = self.image_points)\n",
    "        else:\n",
    "            self.sliding_window = SlidingWindow(self.x_start,\n",
    "                                               target_ht    = self.binary_warped.shape[0],\n",
    "                                               image_points = self.image_points)\n",
    "        \n",
    "        return self.sliding_window\n",
    "        \n",
    "    def getLinearWindow(self):\n",
    "        '''\n",
    "        Returns a linear_window used to search image_points for the points of the line.\n",
    "        \n",
    "        Returns:\n",
    "        - linear_window\n",
    "        \n",
    "        Notes:\n",
    "        - There must be at least one line detected previously; it is used as the basis\n",
    "        for the search area for the linear window.\n",
    "        '''\n",
    "        \n",
    "        if self.linear_window:\n",
    "            #--- reuse and reinitizalize existing instance\n",
    "            self.linear_window.reinit(self.lane_line, \n",
    "                                      target_ht    = self.binary_warped.shape[0],\n",
    "                                      image_points = self.image_points)\n",
    "        else:\n",
    "            self.linear_window = LinearWindow(self.lane_line,\n",
    "                                              target_ht    = self.binary_warped.shape[0],\n",
    "                                              image_points = self.image_points)            \n",
    "        return self.linear_window\n",
    "        \n",
    "    def selectLanePointsFinder(self):\n",
    "        '''\n",
    "        Selects the approriate LanePointsFinder to search for lane points.\n",
    "        '''\n",
    "\n",
    "        if self.use_linear_window:\n",
    "            #--- use LinearWindow if lane lines were previously found\n",
    "            self.lane_points_finder = self.getLinearWindow()\n",
    "        else:\n",
    "            #--- use sliding window if lane lines were NOT previously found\n",
    "            self.lane_points_finder = self.getSlidingWindow()\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def findLaneLine (self, binary_warped):\n",
    "        '''\n",
    "        Finds line representing lane of the road using appropriate lane line finder.\n",
    "        '''\n",
    "        \n",
    "        self.binary_warped = binary_warped\n",
    "        \n",
    "        self.findImagePoints()\n",
    "        self.selectLanePointsFinder()\n",
    "        \n",
    "        x_lane_points, y_lane_points = self.lane_points_finder.findPoints()\n",
    "        \n",
    "        #--- TODO: test for x_lane_points, y_lane_points = None, None\n",
    "        \n",
    "        #--- fit the points of the lane onto a line\n",
    "        self.lane_line.fit(x_lane_points, y_lane_points)\n",
    "\n",
    "        #--- generate the points of the line along the image\n",
    "        self.lane_line.generateXY(img_ht=self.binary_warped.shape[0])\n",
    "        \n",
    "        #--- smooth out the line to reduce frame to frame jitter\n",
    "        #--- sets use_linear_window to True if smoothing was successful\n",
    "        self.use_linear_window = self.lane_line.smooth()\n",
    "        \n",
    "        \n",
    "        return \n",
    "    \n",
    "    def radius(self):\n",
    "        '''\n",
    "        Calculate real world radius of curvature.\n",
    "        \n",
    "        Notes:\n",
    "        - Measurement taken at bottom of image; i.e. img_ht - 1\n",
    "        '''\n",
    "        #--- take the radius at the bottom of the image\n",
    "        y = self.binary_warped.shape[1] - 1\n",
    "        R = self.lane_line.radius(y, XM_PER_PIXEL, YM_PER_PIXEL)\n",
    "\n",
    "        msg = \"Radius: {}.\"\n",
    "        self.logger.debug(msg.format(R))\n",
    "        return R\n",
    "        \n",
    "    def baseX (self):\n",
    "        '''\n",
    "        Returns the X coordinate of the lane_line at the bottom of the image.\n",
    "        \n",
    "        Notes:\n",
    "        - Delegates this down to lane_line\n",
    "        - used to help calculate center offset: center - (left.basex + right.basex / 2)\n",
    "        '''\n",
    "        \n",
    "        return self.lane_line.baseX()\n",
    "    \n",
    "    def getPaintPoints(self, flipud=False):\n",
    "        '''\n",
    "        Returns an array of points repesenting the line of the lane for use in draw function.\n",
    "        \n",
    "        Params:\n",
    "        - flipud: option for returning the array of points in reverse order.\n",
    "        \n",
    "        Returns:\n",
    "        - an array of points like [[[x1, y1], [x2, y2], ...]], shape is like (1, numpoints, 2).\n",
    "\n",
    "        Notes:\n",
    "        - Assume the points have already been generated in call to lane_line.fit()\n",
    "        - Points are suitable for using in cv2 draw functions\n",
    "        - If no lanes were found, returns None\n",
    "        - Set flipud (flip unside down) to true; this is useful for flipping an oppposite lane\n",
    "        to form a polygon for a fillpoly call\n",
    "        '''\n",
    "\n",
    "        self.paint_points = self.lane_line.getPoints()\n",
    "\n",
    "        #--- flip points upside down if required; useful for right lane in drawing polygon with left lane\n",
    "        if flipud and self.paint_points is not None:\n",
    "            #--- if you flipud(paint_points), it will be the same \n",
    "            #--- since there is only 1 element in first dimension\n",
    "            #--- first element of paint_points contains the actual points\n",
    "            #--- so flipud (paint_points[0]) then apply np.array([])\n",
    "            return np.array([np.flipud(self.paint_points[0])])\n",
    "        \n",
    "        else:\n",
    "            return self.paint_points\n",
    "    \n",
    "    def paint(self, img):\n",
    "        '''\n",
    "        Paints the points of the line on canvas\n",
    "        \n",
    "        Params:\n",
    "        - img: an RGB image to draw the lane line on.\n",
    "        '''\n",
    "        msg = \"Painting lane.\"\n",
    "        self.logger.debug(msg)\n",
    "        self.lane_line.paint(img)\n",
    "\n",
    "        return\n",
    "    \n",
    "        \n",
    "class LeftLaneLineFinder(LaneLineFinder):\n",
    "    '''\n",
    "    LaneLineFinder for left lane.\n",
    "    \n",
    "    Methods:\n",
    "    - updateXStart: implements base to set the x_start of the LaneLineGenerator\n",
    "    '''\n",
    "\n",
    "    def updateXStart(self):\n",
    "        \n",
    "        #--- get bottom half of image for histogram\n",
    "        bottom_half = self.binary_warped[self.binary_warped.shape[0] // 2:,:]\n",
    "        histogram = np.sum(bottom_half, axis=0)\n",
    "\n",
    "        #--- search only **left** half of histogram\n",
    "        mid_x = histogram.shape[0] // 2\n",
    "        self.x_start = np.argmax(histogram[:mid_x])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "class RightLaneLineFinder(LaneLineFinder):\n",
    "    '''\n",
    "    LaneLineFinder for right lane.\n",
    "    \n",
    "    Methods:\n",
    "    - updateXStart: implements base to set the x_start of the LaneLineGenerator\n",
    "    '''\n",
    "    \n",
    "    def updateXStart(self):\n",
    "        \n",
    "        bottom_half = self.binary_warped[self.binary_warped.shape[0] // 2:,:]\n",
    "        histogram = np.sum(bottom_half, axis=0)\n",
    "\n",
    "        #--- search only **right** half of histogram\n",
    "        mid_x = histogram.shape[0] // 2\n",
    "        self.x_start = mid_x + np.argmax(histogram[mid_x:])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "class AdvancedLaneFinder:\n",
    "    '''\n",
    "    Manages a left and right lane finder to find lanes in a road image\n",
    "    \n",
    "    Methods:\n",
    "    - __init__\n",
    "    - findLanes\n",
    "    - radius \n",
    "    - centerOffset\n",
    "    - paintLaneArea\n",
    "    - \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #--- TODO: calculate fps\n",
    "        \n",
    "        self.logger = logging.getLogger(\"AdvancedLaneFinder\")\n",
    "        \n",
    "        self.left_lane_line_finder  = LeftLaneLineFinder()\n",
    "        self.right_lane_line_finder = RightLaneLineFinder()\n",
    "        \n",
    "        self.avg_radius = None\n",
    "\n",
    "        self.binary_warped = None\n",
    "        \n",
    "        #--- middle x coordinate of image; used for calculating center offset\n",
    "        self.mid           = None\n",
    "        self.center_offset = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def findLanes(self, binary_warped):\n",
    "        \n",
    "        msg = \"---------------------------\"\n",
    "        self.logger.debug(msg)\n",
    "        msg = \"Finding lanes in new frame.\"\n",
    "        self.logger.debug(msg)\n",
    "        msg = \"---------------------------\"\n",
    "        self.logger.debug(msg)\n",
    "        \n",
    "        self.binary_warped = binary_warped\n",
    "        \n",
    "        self.left_lane_line_finder.findLaneLine(binary_warped)\n",
    "        self.right_lane_line_finder.findLaneLine(binary_warped)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def radius(self):\n",
    "        '''\n",
    "        Caculates the radius of curvature as the average reported from left and right lanes\n",
    "        '''\n",
    "\n",
    "        t = 0    #--- sums up radii values\n",
    "        n = 0    #--- count of number of samples\n",
    "        \n",
    "        radius_left = self.left_lane_line_finder.radius()\n",
    "        t  += radius_left if radius_left is not None else 0\n",
    "        n  += 1 if radius_left is not None else 0\n",
    "        \n",
    "        radius_right = self.right_lane_line_finder.radius()\n",
    "        t  += radius_right if radius_right is not None else 0\n",
    "        n  += 1 if radius_right is not None else 0\n",
    "        \n",
    "        msg = \"Radius left and right: {}, {}\"\n",
    "        self.logger.debug(msg.format(radius_left, radius_right))\n",
    "        if n > 0:\n",
    "            self.avg_radius = t / n\n",
    "        else:\n",
    "            self.avg_radius = None\n",
    "\n",
    "        msg = \"AVg Radius: {}.\"\n",
    "        self.logger.debug(msg.format(self.avg_radius))\n",
    "            \n",
    "        return self.avg_radius\n",
    "    \n",
    "    def centerOffset(self):\n",
    "        '''\n",
    "        Caclulates the offset from center in real world meters\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        img_ctr = self.binary_warped.shape[1] // 2\n",
    "        \n",
    "        t = 0    #--- sums up x values\n",
    "        n = 0    #--- count of number of samples\n",
    "\n",
    "        #--- get distance from center\n",
    "        x_left =  self.left_lane_line_finder.baseX()\n",
    "        t  += x_left if x_left is not None else 0\n",
    "        n  += 1 if x_left is not None else 0\n",
    "        \n",
    "        x_right = self.right_lane_line_finder.baseX()\n",
    "        t  += x_right if x_right is not None else 0\n",
    "        n  += 1 if x_right is not None else 0\n",
    "        \n",
    "        if n > 0:\n",
    "            lane_center = t / n\n",
    "            self.center_offset = (lane_center - img_ctr) * XM_PER_PIXEL\n",
    "        else:\n",
    "            self.center_offset = None\n",
    "            \n",
    "        msg = \"Center offset: {}.\"\n",
    "        self.logger.debug(msg.format(self.center_offset * 100))\n",
    "            \n",
    "        return self.center_offset \n",
    "        \n",
    "    def paintLaneArea(self):\n",
    "        '''\n",
    "        Paints the lane and area between lane onto an image\n",
    "        '''\n",
    "        \n",
    "        #---\n",
    "        #--- create the blank image for painting\n",
    "        #---\n",
    "        \n",
    "        #--- black screen [0 0 0 ...]\n",
    "        img_binary = np.zeros_like(self.binary_warped).astype(np.uint8)\n",
    "        \n",
    "        #--- black RGB img [[0 0 0], [0 0 0], [0 0 0], ...]\n",
    "        img = np.dstack((img_binary, img_binary, img_binary))\n",
    "        \n",
    "        #---\n",
    "        #--- paint lanes\n",
    "        #---\n",
    "        self.left_lane_line_finder.paint(img)\n",
    "        self.right_lane_line_finder.paint(img)\n",
    "        \n",
    "        #---\n",
    "        #--- paint area between lanes\n",
    "        #---\n",
    "        \n",
    "        #--- get polygon for lane area by getting paint points of each lane finder\n",
    "        left_lane_paint_points = self.left_lane_line_finder.getPaintPoints()\n",
    "        \n",
    "        #--- need to \"reverse\" right points array so tail of pts_left is next to head of pts_right\n",
    "        #--- this ordering allows fillpoly to traverse around perimeter, \n",
    "        #--- if the order of points is not flipud, the fill will look like a bowtie\n",
    "        right_lane_paint_points = self.right_lane_line_finder.getPaintPoints(flipud=True)\n",
    "        \n",
    "        if left_lane_paint_points is not None and right_lane_paint_points is not None:\n",
    "            #--- combaine paintpoints into a polygon\n",
    "            lane_area_paint_pts = np.hstack((left_lane_paint_points, right_lane_paint_points))\n",
    "\n",
    "            #--- paint the lane area\n",
    "            cv2.fillPoly(img, lane_area_paint_pts, [0,255,0])\n",
    "            \n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HUD:\n",
    "    '''\n",
    "    A simulated heads-up-display; composes the final image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, advanced_lane_finder, image_warper):\n",
    "        \n",
    "        self.alf = advanced_lane_finder\n",
    "        self.iw  = image_warper\n",
    "        \n",
    "        #--- text formatting params\n",
    "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        self.scale = 1\n",
    "        self.color = [255, 255, 255]\n",
    "        self.thickness = 3\n",
    "        \n",
    "        return\n",
    "\n",
    "    def blendImages(self, img_undistorted):\n",
    "        '''\n",
    "        Annotates original road image with lane area found\n",
    "        '''\n",
    "    \n",
    "        lane_area_warped   = self.alf.paintLaneArea()\n",
    "        lane_area          = self.iw.unwarpPerspective(lane_area_warped)\n",
    "\n",
    "        self.img_lane_area = cv2.addWeighted(img_undistorted, \n",
    "                                             alpha = 1.0, \n",
    "                                             src2  = lane_area, \n",
    "                                             beta  = 0.3, \n",
    "                                             gamma = 0.0)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def putRadius(self):\n",
    "        '''\n",
    "        Draws radius of curvature indicator on image.\n",
    "        '''\n",
    "    \n",
    "        radius = self.alf.radius()\n",
    "        if radius is None:\n",
    "            rad_str = \"Radius:\"\n",
    "        else:\n",
    "            msg = \"Radius: {:.2f} km\"\n",
    "            rad_str = msg.format (radius / 1000)\n",
    "        \n",
    "        cv2.putText(self.img_lane_area, rad_str, (50, 50), self.font, self.scale, self.color, self.thickness)\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def putCenterOffset(self):\n",
    "        '''\n",
    "        Draws radius of curvature indicator on image.\n",
    "        '''\n",
    "        \n",
    "        center_offset = self.alf.centerOffset()\n",
    "        if center_offset is None:\n",
    "            off_str = \"Center offset \"\n",
    "        else:\n",
    "            if abs (center_offset) < 0.1:  #--- 0.1 m or 10 cm\n",
    "                #--- if it's within 10cm it's on centerline...comeon!!!!\n",
    "                off_str = \"Roughly on centerline!\"\n",
    "            else:\n",
    "                if center_offset > 0:\n",
    "                    msg = \"Center Offset: {:.0f} cm Right\"\n",
    "                else:\n",
    "                    msg = \"Center Offset: {:.0f} cm Left\"\n",
    "                off_str = msg.format (abs(center_offset * 100))\n",
    "        \n",
    "        cv2.putText(self.img_lane_area, off_str, (50, 100), self.font, self.scale, self.color, self.thickness)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def compose(self, img_undistorted):\n",
    "        \n",
    "        self.blendImages(img_undistorted)\n",
    "        \n",
    "        self.putRadius()\n",
    "        self.putCenterOffset()\n",
    "        \n",
    "        return self.img_lane_area\n",
    "\n",
    "    def imshow(self):\n",
    "    \n",
    "        plt.figure(figsize=(11, 6.5))\n",
    "        plt.imshow(self.img_lane_area)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logging()\n",
    "cam = Camera()\n",
    "le  = LaneEnhancer()\n",
    "iw  = ImageWarper()\n",
    "alf = AdvancedLaneFinder()\n",
    "hud = HUD(alf, iw)\n",
    "\n",
    "cam.calibrateCamera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img_undistorted = cam.undistort(img)\n",
    "    binary          = le.enhance(img_undistorted)    \n",
    "    binary_warped   = iw.warpPerspective(binary)\n",
    "    alf.findLanes(binary_warped)  #--- TODO: change this\n",
    "    final_img       = hud.compose(img_undistorted)\n",
    "    return final_img\n",
    "    #return cv2.cvtColor(binary * 255, cv2.COLOR_GRAY2RGB)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "fname = \"challenge_video.mp4\"\n",
    "# fname = \"project_video.mp4\"\n",
    "\n",
    "white_output = \"output_images/out_\" + fname\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(fname)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test area below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "img_undistorted = cam.undistort(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6.5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(img_undistorted)\n",
    "\n",
    "# warped = camera.warpPerspective(curved_img)\n",
    "# plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test6.jpg')\n",
    "#--- img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "img_undistorted = cam.undistort(img)\n",
    "\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(img_undistorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = le.enhance(img_undistorted)\n",
    "plt.imshow(cv2.cvtColor(binary * 255, cv2.COLOR_GRAY2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_warped = iw.warpPerspective(binary)\n",
    "plt.imshow(binary_warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.findLanes(binary_warped)\n",
    "hud.compose(img_undistorted)\n",
    "hud.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alf.findLanes(binary_warped)\n",
    "\n",
    "\n",
    "lane_area_warped = alf.paintLaneArea(binary_warped)\n",
    "\n",
    "lane_area = image_warper.unwarpPerspective(lane_area_warped)\n",
    "\n",
    "result = cv2.addWeighted(img_undistorted, 1, lane_area, 0.3, 0)\n",
    "\n",
    "\n",
    "#---\n",
    "#--- Paint radius and center offet text\n",
    "#---\n",
    "if alf.avg_radius is None:\n",
    "    rad_str = \"Radius:\"\n",
    "else:\n",
    "    msg = \"Radius: {:.2f} km\"\n",
    "    rad_str = msg.format (alf.avg_radius / 1000)\n",
    "\n",
    "if alf.center_offset is None:\n",
    "    off_str = \"Center offset \"\n",
    "else:\n",
    "    if alf.center_offset == 0:\n",
    "        off_str = \"On centerline\"\n",
    "    else:\n",
    "        if alf.center_offset > 0:\n",
    "            msg = \"Center Offset: {:.0f} cm Right\"\n",
    "        else:\n",
    "            msg = \"Center Offset: {:.0f} cm Left\"\n",
    "\n",
    "        off_str = msg.format (abs(alf.center_offset * 100))\n",
    "\n",
    "fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = [255, 255, 255]\n",
    "thickness = 3\n",
    "\n",
    "cv2.putText(result, rad_str, (50, 50), fontFace, fontScale, color, thickness)\n",
    "cv2.putText(result, off_str, (50, 100), fontFace, fontScale, color, thickness)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.array([0, 1, 2, 3, 4, 5, 6, 7, 3, 4,5, 6, 6,4, 5])\n",
    "\n",
    "y = 7\n",
    "\n",
    "x = np.array([9, 10, 11, 12, 13, 14, 15, 16])\n",
    "\n",
    "def f(x, yin):\n",
    "    \n",
    "    y = np.array([yin]).flatten()\n",
    "    \n",
    "    if all (0 <= y) and all (y < x.size):\n",
    "        #--- since the points have been generated\n",
    "        #--- just look up the x coordinate for x_line_points\n",
    "        r = x[y]\n",
    "    else:\n",
    "        r = \"outside\"\n",
    "    return r\n",
    "    \n",
    "print (type(f(x, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 3, 4], [4, 5, 6]]\n",
    "b = np.average(a, axis=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(30).reshape((10,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([8, 9, 10])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "c = a-b\n",
    "c\n",
    "x1, x2, x3 = c\n",
    "x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([2, 3, 4])\n",
    "l = c < 2 * d\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "a[:-1] = a[1:]\n",
    "a[-1] = 4\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1])\n",
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = None\n",
    "rad_str = \"Radius: {:.0f}\"\n",
    "s = rad_str.format (v)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "b = 4\n",
    "if a != b:\n",
    "    print(\"thjis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "'''\n",
    "BaselineImage: use for setting setting transformation matrix\n",
    "'''    \n",
    "class BaselineImage:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "        \n",
    "        #--- src and dst points for perspective transformations\n",
    "        #--- coordinages were derived from manual measurement\n",
    "        '''\n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451], [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[191,   0], [1123,  0], [1123, 719], [211, 719]])\n",
    "        \n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451], [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[391,   0], [923,   0], [923,  719], [391, 719]])\n",
    "        '''\n",
    "        self.src_points = np.float32 ([[592, 451], [688, 451],  [1123, 719], [191, 719]])\n",
    "        self.dst_points = np.float32 ([[291,   0], [1023,   0], [1023, 719], [291, 719]])\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def showSrcPoints(self):\n",
    "        plt.imshow(img)\n",
    "        for i in range(4):\n",
    "            plt.plot(source_points[i][0], source_points[i][1], '.')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_logging()\n",
    "\n",
    "chessboard_images = ChessboardImages()\n",
    "chessboard_images.loadChessboardImages() \n",
    "chessboard_images.findChessboardCorners()\n",
    "camera = Camera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.calibrateCamera(chessboard_images)\n",
    "idx=0\n",
    "img = camera.undistort(chessboard_images.getChessboardImg(idx))\n",
    "plt.subplot(121).imshow(chessboard_images.getChessboardImg(idx))\n",
    "plt.subplot(122).imshow(img)\n",
    "\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_image = BaselineImage()\n",
    "camera.updateM(baseline_image.src_points, baseline_image.dst_points)\n",
    "warped = camera.warpPerspective(camera.baseline_image.img)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curved_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "warped = camera.warpPerspective(curved_img)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwarped = camera.unwarpPerspective(warped)\n",
    "plt.imshow(unwarped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient and Colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def h_channel (self, img, t_min=18, t_max=50):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        h_channel = hls[:,:,0]\n",
    "        \n",
    "        mask = np.zeros_like(h_channel)\n",
    "        mask[(t_min <= h_channel) & (h_channel <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    \n",
    "    #--- we reuse the test_highlight_yellow_and_white above\n",
    "    def yellow_white(self, img):\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        mask_yellow = cv2.inRange(hsv, yellow_range[0], yellow_range[1])\n",
    "        mask_white  = cv2.inRange(hsv, white_range[0], white_range[1])\n",
    "\n",
    "        mask = mask_yellow + mask_white\n",
    "\n",
    "        return mask\n",
    "yellow_range = [np.array([20,  70,   0]), \n",
    "                np.array([40, 255, 255])]\n",
    "\n",
    "white_range  = [np.array([  0,  0, 180]), \n",
    "                np.array([179, 25, 255])]\n",
    "\n",
    "        \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class LaneEdgeMasker:\n",
    "    def __init__(self):\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def Sobel_x(self, img, t_min=20, t_max=255):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, dx=1, dy=0))\n",
    "        sobel_scaled = np.uint8(255 * sobel / np.max(sobel))\n",
    "        \n",
    "        mask = np.zeros_like(sobel_scaled)\n",
    "        mask[(t_min <= sobel_scaled) & (sobel_scaled <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def s_channel (self, img, t_min=125, t_max=255):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        \n",
    "        mask = np.zeros_like(s_channel)\n",
    "        mask[(t_min <= s_channel) & (s_channel <= t_max)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "masker = LaneEdgeMasker()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask = masker.Sobel_x(curved_img)\n",
    "plt.imshow(x_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_warped = camera.warpPerspective(x_mask)\n",
    "plt.imshow(x_warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mask = masker.s_channel(curved_img)\n",
    "plt.imshow(s_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_warped = camera.warpPerspective(s_mask)\n",
    "plt.imshow(s_warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask = s_warped | x_warped\n",
    "plt.imshow(all_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(mask):\n",
    "    \n",
    "    bottom_half = mask[mask.shape[0] // 2:,:]\n",
    "    hist = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "h = hist(all_mask)\n",
    "plt.plot(h)\n",
    "print (h.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_x = h.shape[0] //2\n",
    "\n",
    "left_x_mid = np.argmax(h[:mid_x])\n",
    "right_x_mid = mid_x + np.argmax(h[mid_x:])\n",
    "print (left_x_mid, right_x_mid)\n",
    "print (h[left_x_mid], h[right_x_mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((1,15))\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OldSlidingWindow:\n",
    "    \n",
    "    def __init__(self, x_mid, target_ht, image_points, \n",
    "                 num_segments = 8, x_offset=100, numpoints_found_thresh = 50):\n",
    "\n",
    "        #--- x1 = x_mid - offset, x2 = x_mid + offset\n",
    "        self.x_mid    = x_mid\n",
    "        self.x_offset = x_offset\n",
    "        self.x1       = x_mid - x_offset\n",
    "        self.x2       = x_mid + x_offset\n",
    "        \n",
    "        self.ht = target_ht // num_segments\n",
    "        self.y2 = target_ht   #--- y2 is bottom of image\n",
    "        self.y1 = self.y2 - self.ht\n",
    "        \n",
    "        #--- number of points found to calculate\n",
    "        #--- average x for next mid point when window slides up\n",
    "        self.numpoints_found_thresh = numpoints_found_thresh\n",
    "        \n",
    "        #--- unpack image points which are all the nonzero points in target image\n",
    "        #--- point (image_points_x[i], image_points_y[i]) is a nonzero point in target image\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        #--- true if window has slid passed the top of the target image\n",
    "        self.passed_top = False\n",
    "        \n",
    "        #--- holds all image points found in current window using find_points\n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        #--- holds coordinates of windows borders as it is slid up\n",
    "        #--- used for demo\n",
    "        self.window_history = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def findPoints(self):\n",
    "        '''\n",
    "        Finds points in image_points that are in window.\n",
    "        \n",
    "        - Accumulates points found in lane_points\n",
    "        - Call slideUp() after findPoints, otherwise, duplicate points may be collected\n",
    "        - mid_x updated to average of x points found\n",
    "        '''\n",
    "        \n",
    "        while not self.passed_top:        \n",
    "            \n",
    "            self.window_history.append([self.x1, self.y1, self.x2, self.y2])\n",
    "            \n",
    "            #--- mask in all points within window by x and y values\n",
    "            x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "            y_bool_mask = (self.y1 <= self.image_points_y) & (self.image_points_y <= self.y2)\n",
    "\n",
    "            #--- bit wise the x and y masks to get the actual points\n",
    "            xy_bool_mask = (x_bool_mask) & (y_bool_mask)\n",
    "\n",
    "            #--- apply mask to image_points_x and _y to find the points that are in window region\n",
    "            points_found_x = self.image_points_x[xy_bool_mask]\n",
    "            points_found_y = self.image_points_y[xy_bool_mask]\n",
    "\n",
    "            #--- collect the points found into lane_points_x and _y\n",
    "            #--- if window is not slid up after call to findpoints, \n",
    "            #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "            self.lane_points_x.extend(points_found_x)\n",
    "            self.lane_points_y.extend(points_found_y)\n",
    "\n",
    "            #--- update the midpoint if enough points found above threshold\n",
    "            if len(points_found_x) >= self.numpoints_found_thresh:\n",
    "                #--- must be INT! or \n",
    "                self.x_mid = np.int(np.average(points_found_x))\n",
    "                \n",
    "            self.slideUp()\n",
    "        \n",
    "        return \n",
    "    \n",
    "    \n",
    "    def slideUp (self):\n",
    "        '''\n",
    "        Updates window position by decreasing y1 and y2\n",
    "        \n",
    "        - y2 updated first to one line above y1\n",
    "        - y1 is then updated to y2 - height of window\n",
    "        - if y2 <= 0, then window has reached the top\n",
    "        - x1 and x2 are updated in case find_points updated xmid\n",
    "        '''\n",
    "        \n",
    "        #--- update y2 (bottom) of window to line above top\n",
    "        self.y2 = self.y1 - 1\n",
    "        \n",
    "        if self.y2 > 0:\n",
    "            self.y1 = self.y1 - self.ht - 1\n",
    "            if self.y1 < 0:\n",
    "                #--- set y1 to 0 if y1 is below 0\n",
    "                self.y1 = 0\n",
    "\n",
    "            self.x1 = self.x_mid - self.x_offset\n",
    "            self.x2 = self.x_mid + self.x_offset\n",
    "\n",
    "        else:\n",
    "            self.passed_top = True\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "class LineWindow:\n",
    "    \n",
    "    def __init__ (self, line, target_ht, image_points, x_offset=100):\n",
    "        \n",
    "        self.line = line\n",
    "        self.ht = target_ht\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        self.x1 = line.X(self.image_points_y) - x_offset\n",
    "        self.x2 = self.x1 + x_offset + x_offset\n",
    "        \n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def findPoints (self):\n",
    "        \n",
    "        #--- mask in all points within window by x values\n",
    "        x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "        \n",
    "        #--- apply mask to image_points_x and _y to find the points that are in window region\n",
    "        points_found_x = self.image_points_x[x_bool_mask]\n",
    "        points_found_y = self.image_points_y[x_bool_mask]\n",
    "        \n",
    "        #--- collect the points found into lane_points_x and _y\n",
    "        #--- if window is not slid up after call to findpoints, \n",
    "        #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "        self.lane_points_x.extend(points_found_x)\n",
    "        self.lane_points_y.extend(points_found_y)\n",
    "        \n",
    "        return\n",
    "        \n",
    "\n",
    "\n",
    "class OldLine:\n",
    "    \n",
    "    def __init__(self, x, y, polyfit_tries = 10):\n",
    "        \n",
    "        self.logger = logging.getLogger(\"Line\")\n",
    "        \n",
    "        #--- needed to use error handling for calls to polyfit\n",
    "        #--- would cause \"SVD\" did not converge error in jupyter notebook every other run\n",
    "        #--- polyfit will likely succeed on second try\n",
    "        #--- discussion: https://github.com/numpy/numpy/issues/16744 says its due to windows\n",
    "        \n",
    "        tries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                tries += 1\n",
    "                #--- we solve for X!!! i.e. x = ay**2 + by + C\n",
    "                fit = np.polyfit(y, x, deg=2)\n",
    "                if tries > 1:\n",
    "                    msg = \"Polyfit succeeded on try {}.\"\n",
    "                    self.logger.warning(msg.format(tries))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if tries < polyfit_tries:\n",
    "                    msg = \"Polyfit failed: {}. Trying again.\"\n",
    "                    self.logger.warning(msg.format(e))\n",
    "                    continue\n",
    "                else:\n",
    "                    msg = \"Polyfit failed. {}.\"\n",
    "                    self.logger.error(msg)\n",
    "                    \n",
    "        '''\n",
    "        fit = np.polyfit(y, x, deg=2)\n",
    "        \n",
    "        '''\n",
    "                \n",
    "        self.a = fit[0]   # coeff for y**2\n",
    "        self.b = fit[1]   # coeff for y\n",
    "        self.c = fit[2]   # constant\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def generatePoints(self, img_ht):\n",
    "        '''\n",
    "        Generates the x and y coordinates of the line along the height of the image.\n",
    "        '''\n",
    "        \n",
    "        #--- generate y points from 0 to img_ht - 1\n",
    "        y_line_points = np.array([float(y) for y in range(img_ht)])\n",
    "                                 \n",
    "        #--- calculate points based on x\n",
    "        x_line_points = self.X(y_line_points)\n",
    "        \n",
    "        return x_line_points, y_line_points\n",
    "    \n",
    "    \n",
    "    def X(self, y):\n",
    "        '''\n",
    "        Generates x-coordinates given y-coordinates\n",
    "        '''\n",
    "        \n",
    "        x = self.a * y**2 + self.b * y + self.c\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "class LineGenerator:\n",
    "    \n",
    "    def __init__(self, lane_warped_img_binary):\n",
    "        \n",
    "        self.img_binary   = lane_warped_img_binary\n",
    "        \n",
    "        \n",
    "    def findStartingX(self):\n",
    "        \n",
    "        y_mid = self.img_binary.shape[0] // 2\n",
    "        img_binary_bottom_half = self.img_binary[y_mid:, :]\n",
    "        \n",
    "        hist    = np.sum(img_binary_bottom_half, axis=0)\n",
    "        x_mid   = self.img_binary.shape[1] // 2\n",
    "        \n",
    "        self.x_start_left  = np.argmax(hist[:x_mid])\n",
    "        self.x_start_right = np.argmax(hist[x_mid:]) + x_mid\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def findImagePoints(self):\n",
    "        \n",
    "        nonzero_points = np.nonzero(self.img_binary)\n",
    "        \n",
    "        #--- y (row) points come first!!! index 0\n",
    "        #--- x (col) points are in second!!! index 1\n",
    "        self.image_points_y = np.array(nonzero_points[0])\n",
    "        self.image_points_x = np.array(nonzero_points[1])\n",
    "        \n",
    "        self.image_points = (self.image_points_x, self.image_points_y)\n",
    "        \n",
    "        return \n",
    "        \n",
    "        \n",
    "    def findLinesDemo(self):\n",
    "        \n",
    "        demo_img = np.dstack((self.img_binary * 255, self.img_binary * 255, self.img_binary * 255))\n",
    "        \n",
    "        self.findStartingX()\n",
    "        self.findImagePoints()\n",
    "        \n",
    "        left_window     = SlidingWindow(self.x_start_left,  self.img_binary.shape[0], self.image_points)\n",
    "        right_window    = SlidingWindow(self.x_start_right, self.img_binary.shape[0], self.image_points)\n",
    "\n",
    "        lines_found  = []\n",
    "        windows      = [left_window, right_window]\n",
    "        point_colors = [[255, 0, 0], [0, 0, 255]]\n",
    "        for window, point_color in zip(windows, point_colors):\n",
    "            \n",
    "            window.findPoints()\n",
    "                    \n",
    "            if window.lane_points_x:\n",
    "                #--- create the line based on the lane points found\n",
    "                line = Line(window.lane_points_x, window.lane_points_y)\n",
    "                lines_found.append(line)\n",
    "                demo_img[window.lane_points_y, window.lane_points_x] = point_color\n",
    "\n",
    "        plt.figure(figsize=(11, 6.5))\n",
    "        for line in lines_found:\n",
    "            x_line_points, y_line_points = line.generatePoints(self.img_binary.shape[0])\n",
    "            plt.plot(x_line_points, y_line_points, color='yellow')\n",
    "        plt.imshow(demo_img)\n",
    "        \n",
    "        return lines_found\n",
    "    \n",
    "    \n",
    "    def findLines(self):\n",
    "        \n",
    "        self.findStartingX()\n",
    "        self.findImagePoints()\n",
    "        \n",
    "        left_window  = SlidingWindow(self.x_start_left,  self.img_binary.shape[0], self.image_points)\n",
    "        right_window = SlidingWindow(self.x_start_right, self.img_binary.shape[0], self.image_points)\n",
    "\n",
    "        self.lines_found  = []\n",
    "        windows      = [left_window, right_window]\n",
    "        for window in windows:\n",
    "            \n",
    "            window.findPoints()\n",
    "                    \n",
    "            if window.lane_points_x:\n",
    "                #--- create the line based on the lane points found\n",
    "                line = Line(np.array(window.lane_points_x), np.array(window.lane_points_y))\n",
    "                self.lines_found.append(line)\n",
    "\n",
    "        return self.lines_found\n",
    "    \n",
    "    \n",
    "    def findLinesLineWindow(self):\n",
    "        \n",
    "        demo_img = np.dstack((self.img_binary * 255, self.img_binary * 255, self.img_binary * 255))\n",
    "        \n",
    "        line_windows = []\n",
    "        for line in self.lines_found:\n",
    "            line_window = LineWindow(line, self.img_binary.shape[0], self.image_points)\n",
    "            line_windows.append(line_window)\n",
    "\n",
    "        self.lines_found = []\n",
    "        for line_window in line_windows:\n",
    "            line_window.findPoints()\n",
    "            \n",
    "            if line_window.lane_points_x:\n",
    "                #--- create the line based on the lane points found\n",
    "                line = Line(line_window.lane_points_x, line_window.lane_points_y)\n",
    "                self.lines_found.append(line)\n",
    "            \n",
    "        plt.figure(figsize=(11, 6.5))\n",
    "        for line in self.lines_found:\n",
    "            x_line_points, y_line_points = line.generatePoints(self.img_binary.shape[0])\n",
    "            plt.plot(x_line_points, y_line_points, color='yellow')\n",
    "        plt.imshow(demo_img)\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "            \n",
    "lineGenerator = LineGenerator(all_mask)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdvancedLaneDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lineGenerator.findLines()\n",
    "print (lines[0].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lineGenerator.findLinesLineWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([34, 35, 12 , 45, 56])\n",
    "y = np.array([432, 123, 40 , 125, 456])\n",
    "m = (12 <= x) & (x <= 35)\n",
    "n = (430 <= y) & (y <= 435)\n",
    "print (m)\n",
    "print (n)\n",
    "x_points = x[m & n]\n",
    "y_points = y[m & n]\n",
    "print (np.stack((x_points, y_points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    \n",
    "    def __init__(self, x_mid, target_ht, image_points, \n",
    "                 num_segments = 8, x_offset=100, numpoints_found_thresh = 50):\n",
    "\n",
    "        #--- x1 = x_mid - offset, x2 = x_mid + offset\n",
    "        self.x_mid    = x_mid\n",
    "        self.x_offset = x_offset\n",
    "        self.x1       = x_mid - x_offset\n",
    "        self.x2       = x_mid + x_offset\n",
    "        \n",
    "        self.ht = target_ht // num_segments\n",
    "        self.y2 = target_ht   #--- y2 is bottom of image\n",
    "        self.y1 = self.y2 - self.ht\n",
    "        \n",
    "        #--- number of points found to calculate\n",
    "        #--- average x for next mid point when window slides up\n",
    "        self.numpoints_found_thresh = numpoints_found_thresh\n",
    "        \n",
    "        #--- unpack image points which are all the nonzero points in target image\n",
    "        #--- point (image_points_x[i], image_points_y[i]) is a nonzero point in target image\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        #--- true if window has slid passed the top of the target image\n",
    "        self.passed_top = False\n",
    "        \n",
    "        #--- holds all image points found in current window using find_points\n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        #--- holds coordinates of windows borders as it is slid up\n",
    "        #--- used for demo\n",
    "        self.window_history = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def reinit (self, x_mid, target_ht, image_points, \n",
    "                 num_segments = 8, x_offset=100, numpoints_found_thresh = 50):\n",
    "        \n",
    "        self.__init__(x_mid, target_ht, image_points, \n",
    "                 num_segments, x_offset, numpoints_found_thresh)\n",
    "        return\n",
    "        \n",
    "    \n",
    "    \n",
    "    def findPoints(self):\n",
    "        '''\n",
    "        Finds points in image_points that are in window.\n",
    "        \n",
    "        - Accumulates points found in lane_points\n",
    "        - Call slideUp() after findPoints, otherwise, duplicate points may be collected\n",
    "        - mid_x updated to average of x points found\n",
    "        '''\n",
    "        \n",
    "        while not self.passed_top:        \n",
    "            \n",
    "            self.window_history.append([self.x1, self.y1, self.x2, self.y2])\n",
    "            \n",
    "            #--- mask in all points within window by x and y values\n",
    "            x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "            y_bool_mask = (self.y1 <= self.image_points_y) & (self.image_points_y <= self.y2)\n",
    "\n",
    "            #--- bit wise the x and y masks to get the actual points\n",
    "            xy_bool_mask = (x_bool_mask) & (y_bool_mask)\n",
    "\n",
    "            #--- apply mask to image_points_x and _y to find the points that are in window region\n",
    "            points_found_x = self.image_points_x[xy_bool_mask]\n",
    "            points_found_y = self.image_points_y[xy_bool_mask]\n",
    "\n",
    "            #--- collect the points found into lane_points_x and _y\n",
    "            #--- if window is not slid up after call to findpoints, \n",
    "            #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "            self.lane_points_x.extend(points_found_x)\n",
    "            self.lane_points_y.extend(points_found_y)\n",
    "\n",
    "            #--- update the midpoint if enough points found above threshold\n",
    "            if len(points_found_x) >= self.numpoints_found_thresh:\n",
    "                #--- must be INT! or \n",
    "                self.x_mid = np.int(np.average(points_found_x))\n",
    "                \n",
    "            self.slideUp()\n",
    "        \n",
    "        return (self.lane_points_x, self.lane_points_y)\n",
    "    \n",
    "    \n",
    "    def slideUp (self):\n",
    "        '''\n",
    "        Updates window position by decreasing y1 and y2\n",
    "        \n",
    "        - y2 updated first to one line above y1\n",
    "        - y1 is then updated to y2 - height of window\n",
    "        - if y2 <= 0, then window has reached the top\n",
    "        - x1 and x2 are updated in case find_points updated xmid\n",
    "        '''\n",
    "        \n",
    "        #--- update y2 (bottom) of window to line above top\n",
    "        self.y2 = self.y1 - 1\n",
    "        \n",
    "        if self.y2 > 0:\n",
    "            self.y1 = self.y1 - self.ht - 1\n",
    "            if self.y1 < 0:\n",
    "                #--- set y1 to 0 if y1 is below 0\n",
    "                self.y1 = 0\n",
    "\n",
    "            self.x1 = self.x_mid - self.x_offset\n",
    "            self.x2 = self.x_mid + self.x_offset\n",
    "\n",
    "        else:\n",
    "            self.passed_top = True\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "class LinearWindow:\n",
    "    \n",
    "    def __init__ (self, line, target_ht, image_points, x_offset=100):\n",
    "        \n",
    "        self.line = line\n",
    "        self.ht = target_ht\n",
    "        self.image_points_x, self.image_points_y = image_points\n",
    "        \n",
    "        self.x1 = line.X(self.image_points_y) - x_offset\n",
    "        self.x2 = self.x1 + x_offset + x_offset\n",
    "        \n",
    "        self.lane_points_x = []\n",
    "        self.lane_points_y = []\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def reinit (self, line, target_ht, image_points, x_offset=100):\n",
    "        \n",
    "        self.__init__(self, line, target_ht, image_points, x_offset)\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    \n",
    "    def findPoints (self):\n",
    "        \n",
    "        #--- mask in all points within window by x values\n",
    "        x_bool_mask = (self.x1 <= self.image_points_x) & (self.image_points_x <= self.x2)\n",
    "        \n",
    "        #--- apply mask to image_points_x and _y to find the points that are in window region\n",
    "        points_found_x = self.image_points_x[x_bool_mask]\n",
    "        points_found_y = self.image_points_y[x_bool_mask]\n",
    "        \n",
    "        #--- collect the points found into lane_points_x and _y\n",
    "        #--- if window is not slid up after call to findpoints, \n",
    "        #--- then lane_points may contain duplicate points on next call to findpoints\n",
    "        self.lane_points_x.extend(points_found_x)\n",
    "        self.lane_points_y.extend(points_found_y)\n",
    "        \n",
    "        return self.lane_points_x, self.lane_points_y\n",
    "    \n",
    "\n",
    "class Line:\n",
    "    '''\n",
    "    descritpion\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, x, y, polyfit_tries = 10):\n",
    "        \n",
    "        self.logger = logging.getLogger(\"Line\")\n",
    "        \n",
    "        #--- needed to use error handling for calls to polyfit\n",
    "        #--- would cause \"SVD\" did not converge error in jupyter notebook every other run\n",
    "        #--- polyfit will likely succeed on second try\n",
    "        #--- discussion: https://github.com/numpy/numpy/issues/16744 says its due to windows\n",
    "        \n",
    "        tries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                tries += 1\n",
    "                #--- we solve for X!!! i.e. x = ay**2 + by + C\n",
    "                fit = np.polyfit(y, x, deg=2)\n",
    "                if tries > 1:\n",
    "                    msg = \"Polyfit succeeded on try {}.\"\n",
    "                    self.logger.warning(msg.format(tries))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if tries < polyfit_tries:\n",
    "                    msg = \"Polyfit failed: {}. Trying again.\"\n",
    "                    self.logger.warning(msg.format(e))\n",
    "                    continue\n",
    "                else:\n",
    "                    msg = \"Polyfit failed. {}.\"\n",
    "                    self.logger.error(msg)\n",
    "                    \n",
    "        '''\n",
    "        fit = np.polyfit(y, x, deg=2)\n",
    "        \n",
    "        '''\n",
    "                \n",
    "        self.a = fit[0]   # coeff for y**2\n",
    "        self.b = fit[1]   # coeff for y\n",
    "        self.c = fit[2]   # constant\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def generatePoints(self, img_ht):\n",
    "        '''\n",
    "        Generates the x and y coordinates of the line along the height of the image.\n",
    "        \n",
    "        parameters:\n",
    "        - img_ht: height of image\n",
    "        \n",
    "        returns:\n",
    "        - x_points: array of the x coordinates of the line in int32\n",
    "        - y_points: array of y coordinates of the line in int32\n",
    "        '''\n",
    "        \n",
    "        #--- generate y points from 0 to img_ht - 1, cast to int32 for ease of plotting\n",
    "        y_line_points = np.int32 (np.array([float(y) for y in range(img_ht)]))\n",
    "                                 \n",
    "        #--- calculate points based on x, cast to int32 for ease of plotting\n",
    "        x_line_points = np.int32 (self.X(y_line_points))\n",
    "        \n",
    "        return x_line_points, y_line_points\n",
    "    \n",
    "    \n",
    "    def X(self, y):\n",
    "        '''\n",
    "        Generates x-coordinates given y-coordinates\n",
    "        \n",
    "        - returns x as\n",
    "        '''\n",
    "        \n",
    "        x = self.a * y**2 + self.b * y + self.c\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class LaneDetector:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.logger = logging.getLogger(\"LaneDetector\")\n",
    "        \n",
    "        self.binary_warped = None\n",
    "        \n",
    "        self.x_start       = None\n",
    "        self.image_points  = None\n",
    "        self.lane_lines    = []\n",
    "        \n",
    "        #--- must be a class that implements findPoints() and returns a Line\n",
    "        self.lane_points_finder = None\n",
    "        self.sliding_window = None\n",
    "        self.linear_window = None\n",
    "        \n",
    "        #--- points of the lane line in ([[x1, y1], [x2, y2], ...) format that is used in cv2 drawing functions\n",
    "        self.paint_points = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateXStart(self):\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def getLaneColor(self):\n",
    "        '''\n",
    "        gets color used for painting lane line\n",
    "        \n",
    "        - defaults to red\n",
    "        - change in descendent classes to \n",
    "        '''\n",
    "        \n",
    "        return [255, 0, 0]\n",
    "    \n",
    "    def findImagePoints(self):\n",
    "        \n",
    "        nonzero_points = np.nonzero(self.binary_warped)\n",
    "        \n",
    "        #--- y (row) points come first!!! index 0\n",
    "        #--- x (col) points are in second!!! index 1\n",
    "        image_points_y = np.array(nonzero_points[0])\n",
    "        image_points_x = np.array(nonzero_points[1])\n",
    "        \n",
    "        self.image_points = (image_points_x, image_points_y)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def getSlidingWindow(self):\n",
    "\n",
    "        self.updateXStart()\n",
    "        if self.sliding_window:\n",
    "            #--- resuse existing and reinitizalize instance\n",
    "            self.sliding_window.reinit(self.x_start,\n",
    "                                      target_ht    = self.binary_warped.shape[0],\n",
    "                                      image_points = self.image_points)\n",
    "        else:\n",
    "            self.sliding_window = SlidingWindow(self.x_start,\n",
    "                                               target_ht    = self.binary_warped.shape[0],\n",
    "                                               image_points = self.image_points)\n",
    "        \n",
    "        return self.sliding_window\n",
    "        \n",
    "    def getLinearWindow(self):\n",
    "        last_lane_line = self.lane_lines[-1]\n",
    "        if self.linear_window:\n",
    "            #--- reuse and reinitizalize existing instance\n",
    "            self.linear_window.reinit(last_lane_line, \n",
    "                                      target_ht    = self.binary_warped.shape[0],\n",
    "                                      image_points = self.image_points)\n",
    "        else:\n",
    "            self.linear_window = LinearWindow(last_lane_line)\n",
    "            \n",
    "        return self.linear_window\n",
    "        \n",
    "    def selectLanePointsFinder(self):\n",
    "        \n",
    "        if self.lane_lines:\n",
    "            self.lane_points_finder = self.getLinearWindow()\n",
    "        else:\n",
    "            self.lane_points_finder = self.getSlidingWindow()\n",
    "            \n",
    "        return\n",
    "            \n",
    "    def checkLaneLine(self, line):\n",
    "        #--- TODO: code this!!!\n",
    "        pass\n",
    "    \n",
    "    def findLaneLine (self, binary_warped):\n",
    "        \n",
    "        self.binary_warped = binary_warped\n",
    "        \n",
    "        self.findImagePoints()\n",
    "        self.selectLanePointsFinder()\n",
    "        \n",
    "        x_lane_points, y_lane_points = self.lane_points_finder.findPoints()\n",
    "        \n",
    "        lane_line = Line(x_lane_points, y_lane_points)\n",
    "        \n",
    "        self.checkLaneLine(lane_line)\n",
    "        self.lane_lines.append(lane_line)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def getPaintPoints(self, canvas, flipud=False):\n",
    "        '''\n",
    "        Returns an array of points repesenting the line of the lane\n",
    "        \n",
    "        Params:\n",
    "        - canvas: an RGB image painting area; just needed to get \n",
    "        the height of the canvas to generate the set of points\n",
    "        - flipud: option for returning the array of points in reverse order\n",
    "        \n",
    "        Returns:\n",
    "        - an array of points like [[[x1, y1], [x2, y2], ...]], shape is like (1, numpoints, 2)\n",
    "\n",
    "        - points are suitable for using in cv2 draw functions\n",
    "        - if no lanes were found, returns None\n",
    "        - set flipud (flip unside down) to true; this is useful for flipping an oppposite lane\n",
    "        to form a polygon for a fillpoly call\n",
    "        \n",
    "        '''\n",
    "\n",
    "        if not self.lane_lines:\n",
    "            return None\n",
    "\n",
    "        if self.paint_points is None: \n",
    "            curr_lane_line = self.lane_lines[-1]\n",
    "            x_points, y_points = curr_lane_line.generatePoints(canvas.shape[0])\n",
    "\n",
    "            #--- combine and transform x_ and y_points to [[x1, y1], [x2, y2], ...]\n",
    "            self.paint_points = np.array([(np.transpose(np.vstack((x_points, y_points))))])\n",
    "            \n",
    "        if flipud:\n",
    "            #--- if you flipud(paint_points), it will be the same \n",
    "            #--- since there is only 1 element in first dimension\n",
    "            #--- first element of paint_points contains the actual points\n",
    "            #--- so flipud (paint_points[0]) then apply np.array([])\n",
    "            return np.array([np.flipud(self.paint_points[0])])\n",
    "        \n",
    "        else:\n",
    "            return self.paint_points\n",
    "    \n",
    "    def paint (self, canvas):\n",
    "        '''\n",
    "        paints the points of the line\n",
    "        '''\n",
    "\n",
    "        cv2.polylines(canvas, \n",
    "                      pts       = self.getPaintPoints(canvas), \n",
    "                      isClosed  = False, \n",
    "                      color     = [255, 0, 0],    #--- default red line color\n",
    "                      thickness = 20)        \n",
    "        return\n",
    "    \n",
    "        \n",
    "class LeftLaneDetector(LaneDetector):\n",
    "\n",
    "    def updateXStart(self):\n",
    "        \n",
    "        bottom_half = self.binary_warped[self.binary_warped.shape[0] // 2:,:]\n",
    "        histogram = np.sum(bottom_half, axis=0)\n",
    "\n",
    "        mid_x = histogram.shape[0] // 2\n",
    "        self.x_start = np.argmax(histogram[:mid_x])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "class RightLaneDetector(LaneDetector):\n",
    "    \n",
    "    def updateXStart(self):\n",
    "        \n",
    "        bottom_half = self.binary_warped[self.binary_warped.shape[0] // 2:,:]\n",
    "        histogram = np.sum(bottom_half, axis=0)\n",
    "\n",
    "        mid_x = histogram.shape[0] // 2\n",
    "        self.x_start = mid_x + np.argmax(histogram[mid_x:])\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ald = AdvancedLaneDetector()\n",
    "ald.findLanes(all_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = ald.paint(all_mask)\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.imshow(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwarpcanvas = camera.unwarpPerspective(canvas)\n",
    "result = cv2.addWeighted(curved_img, 1, unwarpcanvas, 0.3, 0)\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_binary = np.zeros_like(all_mask).astype(np.uint8)\n",
    "canvas = np.dstack((canvas_binary, canvas_binary, canvas_binary))\n",
    "canvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_points, ly_points = ald.left_lane.generatePoints(canvas.shape[0])\n",
    "rx_points, ry_points = ald.right_lane.generatePoints(canvas.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.plot(lx_points, ly_points, color='yellow')\n",
    "plt.plot(rx_points, ry_points, color='yellow')\n",
    "plt.imshow(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6.5))\n",
    "\n",
    "pts_left = np.array([(np.transpose(np.vstack((lx_points, ly_points))))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack((rx_points, ry_points))))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "print (pts.shape)\n",
    "\n",
    "cv2.fillPoly(canvas, np.int_([pts]), [0,255,0])\n",
    "cv2.polylines(canvas, pts_left, False, [255,0,0], 8)\n",
    "cv2.polylines(canvas, pts_right, False, [255,0,0], 8)\n",
    "\n",
    "\n",
    "plt.imshow(canvas)\n",
    "print (canvas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwarpcanvas = camera.unwarpPerspective(canvas)\n",
    "result = cv2.addWeighted(curved_img, 1, unwarpcanvas, 0.3, 0)\n",
    "plt.figure(figsize=(11, 6.5))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "if a.size > 0:\n",
    "    print('not empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "y = [5, 4, 3, 2, 1]\n",
    "np.transpose (np.vstack((x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3, 4, 5], [1,2,3, 4, 5], [1,2,3, 4, 5], [1,2,3, 4, 5], [1,2,3, 4, 5]])\n",
    "s = np.sum(a, axis=0)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = np.array( [[[10,10],[100,10],[100,100],[10,100]]], dtype=np.int32 )\n",
    "a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = np.array( [[[10,10],[100,10],[10,100], [150,100]]], dtype=np.int32 )\n",
    "im = np.zeros([240,320],dtype=np.uint8)\n",
    "cv2.fillPoly( im, a3, 255 )\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    a = 10\n",
    "    return a\n",
    "\n",
    "x = 1\n",
    "x = f(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "ht = img.shape[0] - 1\n",
    "wid = img.shape[1] - 1\n",
    "midx = wid // 2\n",
    "offsetx = 40\n",
    "top = 425\n",
    "bottom = ht\n",
    "\n",
    "#--- XY coords\n",
    "dx1 = 211\n",
    "dx2 = 230\n",
    "\n",
    "\n",
    "'''\n",
    "source_points = np.float32 ([[592, 451],      [688, 451],     [1123, 719], [191, 719]])\n",
    "# source_points = np.float32 ([[485, 530],      [805, 530],     [1104, 719], [211, 719]])\n",
    "\n",
    "dest_points   = np.float32 ([[191, 0],      [1123, 0],     [1123, 719], [211, 719]])\n",
    "# dest_points =   np.float32 ([[634 - dx1,   0],[644 + dx2, 0], [1104 - dx2, 719], [211 + dx1, 719]])\n",
    "\n",
    "'''\n",
    "source_points = np.float32 ([[592, 451],      [688, 451],     [1123, 719], [191, 719]])\n",
    "# source_points = np.float32 ([[485, 530],      [805, 530],     [1104, 719], [211, 719]])\n",
    "\n",
    "dest_points   = np.float32 ([[391, 0],      [923, 0],     [923, 719], [391, 719]])\n",
    "# dest_points =   np.float32 ([[634 - dx1,   0],[644 + dx2, 0], [1104 - dx2, 719], [211 + dx1, 719]])\n",
    "\n",
    "\n",
    "\n",
    "print (source_points)\n",
    "print (dest_points)\n",
    "\n",
    "plt.imshow(img)\n",
    "for i in range(4):\n",
    "    plt.plot(source_points[i][0], source_points[i][1], '.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getPerspectiveTransform(source_points, dest_points)\n",
    "warped = cv2.warpPerspective(img, M, (1280, 720), flags=cv2.INTER_LINEAR)\n",
    "# warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "camera.getPerspectiveTransform(source_points, dest_points)\n",
    "warped = camera.warpPerspective(img)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, corners = cv2.findChessboardCorners(gray, (9, 5), None)\n",
    "if ret:\n",
    "    print (corners.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- chessboard dimensions is in X by Y where X is columns, Y is rows\n",
    "\n",
    "obj_points = np.zeros((9*5, 3), np.float32)\n",
    "obj_points_2 = np.zeros((9*5, 3), np.float32)\n",
    "\n",
    "#--- points are on the XY plane, so Z = 0\n",
    "obj_points[:, :2] = np.mgrid[:9, :5].T.reshape(-1, 2)\n",
    "obj_points_2[:, :2] = np.array([(x, y) for y in range(5) for x in range (9)])\n",
    "\n",
    "# np.mgrid[:9, :5].T.reshape(-1, 2)\n",
    "same = obj_points == obj_points_2\n",
    "#print (same)\n",
    "print (obj_points[:5])\n",
    "print (obj_points_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgrid = np.mgrid[:9, :5]\n",
    "print (mgrid.shape)\n",
    "print (mgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mgrid.T.shape)\n",
    "print (mgrid.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mgrid.T.reshape(-1, 2))\n",
    "print (mgrid.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = mgrid.T.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (coords.shape)\n",
    "print (corners.shape)\n",
    "print (corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.drawChessboardCorners(img, (9, 5), corners, ret)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (4, 5, 3, 2, 8)\n",
    "shape[2::2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
